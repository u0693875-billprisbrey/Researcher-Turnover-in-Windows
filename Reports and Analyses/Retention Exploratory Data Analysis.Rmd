---
title: "Retention Exploratory Data Analysis"
author: "Bill Prisbrey"
date: "2025-04-25"
output: html_document
---



```{r include=FALSE}

# What I'm thinking on 6-04-2025
# Since I'm about to get a ton of data from HR, then I'll basically need to write myself a whole 'nuther EDA.
# So while the first EDA was called "Quick'n'Dirty", I'm going to call this one "Intermediate" or something.  "Partial data" ?
# The idea is that I'll wrap this up as a relatively stand-alone report, where it is, however truncated it is, and explain that it's incomplete because HR is making a much more complete data store available.


# ===
# It's hard to re-write the flow of an existing report.
# I think it's easier to copy to a new place and start over.
# But I'll keep working on adapting this current one (with lots of frequent commits.)

# I like my new direction  -- it's like two chapters.
# Chapter 1 is the retention data by itself -- basically cleaning up the "quick'n'dirty" version.
# Chapter 2 is the combination, which will require adapting the functions and will probably tell a pretty different story.

# This will be quicker to produce than a blend, but it also won't be the best story-telling or have the best narrative flow.

# Notes for author

# I am over-using the word "active."  I think I want "active" to mean the period they are "actively" proposing, and the word "current" to mean they are currently employed.  But what about then-current?  I guess I'll use the word "active" for proposing, and "employed" for then-employed.

# More thoughts:  
#  - Kruskal wallis is a nice general purpose first-look test, but I should probably find something more appropriate.
#  - Digging into how the intervals were aggregated should be informative (am I sure I'm doing it right?)


# Thoughts:

# - Re-name this as "exploratory data analysis" and summarize the new data view.  "Skimr" and a couple of histograms.
# - I'll probably uncover some data inconsistencies.
# - Use my new "activePI" function to calculate the number of active PI's every week.
# - Create a dataframe that is week-by-week active PI's
# - Use prepData to align proposing periods with hire or re-hire period EVENTUALLY
# - Lack of an initial termination date could be problematic

```


**PURPOSE:**  The purpose of this document is to describe the incomplete retention data of principal investigators originally available to the Office of Sponsored Projects.  This is a truncated report and demonstrates a stage in the process.  It is useful as a milestone or reference but should not be used to draw conclusions.    

**OBJECTIVES:**   

  1.  Describe the retention data.
  2.  Calculate and compare turnover    
      a.  By colleges    ***DONE***  
      b.  By PI clusters ***DONE***   
      c.  By percentiles ***DONE***   
  3.  Briefly describe highlights and identify avenues for further exploration and next steps.           

**NOT PERFORMED IN THIS REPORT:**

  1.  Compare the retention data and the proposal data. 
  2.  Re-calculate and compare turnover using estimated hire dates from the comparison.   
  3.  Statistical tests
      


  
```{r include = FALSE}

knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, error=FALSE, fig.height=7, fig.width=10)

# adjust graphic parameters

oldPar <- par(cex.main = 3,
    cex.lab = 3,
    cex.axis = 2,
    mar = c(5.1,4.1,4.1,2.1), # default is c(5.1,4.1,4.1,2.1)
    mfrow = c(1,1)
    )

library(lubridate)

```

```{r}

###########
## QUERY ##
###########

# Obtain retention data

keyring::keyring_unlock(keyring = "BIPR", password = "Excelsior!")

library(DBI)
con.ds <- DBI::dbConnect(odbc::odbc(), Driver = "oracle", Host = "ocm-campus01.it.utah.edu", 
                         SVC = keyring::key_list(keyring = "BIPR")[1, 1], UID = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                    2], PWD = keyring::key_get(keyring = "BIPR", service = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                                                                                                               1]), Port = 2080)
retentionQuery <- "
SELECT *
FROM VPR.D_PI_EMP_DT_VW EMP_DATES
"

retData <- dbGetQuery(con.ds,
                      retentionQuery)


DBI::dbDisconnect(con.ds)




```


```{r}

##########
## LOAD ##
##########

# PREP SCRIPT

source(here::here("Prep scripts","Adjusting prepData and loading things.R"))


# PER PI

piClusters <- lapply(list.files(here::here("Robjects", "Clustering PIs"), full.names = TRUE), readRDS)

###########
## MERGE ## 
###########

piEmplid <- Reduce(function(x, y) {
  merged <- merge(x, y, by = "emplid", all = FALSE)
  merged <- merged[, !duplicated(sub("\\.x$|\\.y$", "", names(merged)))]  # Remove duplicate columns
  
  # Rename columns to remove ".x"
  names(merged) <- sub("\\.x$", "", names(merged))
  
  merged
}, piClusters)
# piEmplid <- Reduce(function(x, y) merge(x, y, by = "emplid", all = FALSE), piClusters)
# piEmplid <- do.call(merge, piClusters)



prepData <- merge(prepData, piEmplid[,c("emplid","complex_cluster","rate_cluster")], by.x =  "PROPOSAL_PI_EMPLID", by.y = "emplid", all.x = TRUE)

##########
## PREP ##
##########

piEmplid$combined_cluster <-  factor(paste(piEmplid$complex_cluster, piEmplid$rate_cluster, sep = ", "))

prepData$combined_cluster <- factor(paste(prepData$complex_cluster, prepData$rate_cluster, sep = ", "))

###############
## LIBRARIES ##
###############

library(viridis)
library(pheatmap)

#########
## MAP ##
#########

piMap <- data.frame(college = row.names(piEmplid), abbrv = row.names(piEmplid), color = NA, pch = 19, cex = 0.7 )

# I need the college map of colors

fullEmplid <- calculateWinRates(data = cleanData, categoryColumn = "PROPOSAL_PI_EMPLID") |>
  (\(x){x[[1]]})()

fullEmplid$count.total <- apply(fullEmplid[,c("win.count","loss.count")],1,sum)

filterTwoCount <- fullEmplid$count.total >= 2
# filterThreeCount <- piEmplid$count.total > 3


```


```{r}
             
# Manage colors

#############
## COMPLEX ##
#############

complexClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
                            "firebrick", "darkslategray", "chartreuse",  
                            "slateblue", "darkkhaki", "coral")

names(complexClusterColors) <- c(as.character(1:5),"unassigned") # I'll surely regret this

clusterComplexMapping <- piMap
clusterComplexMapping[,"pch"] <- rep(19, nrow(clusterComplexMapping))

clusterComplexMapping[,"color"] <- complexClusterColors [piEmplid$complex_cluster]

# clusterComplexMapping[,"color"] <- complexClusterColors[complexHCPC$data.clust$clust[match(clusterComplexMapping[,"college"], row.names(complexHCPC$data.clust))] ]

##############
## COMBINED ##
##############

combinedClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
  "firebrick", "darkslategray", "chartreuse",  
  "slateblue", "darkkhaki", "coral",  
  "mediumorchid", "dodgerblue", "tomato",  
  "orchid", "darkseagreen", "sienna",  
  "royalblue", "indianred", "seagreen",  
  "peru", "cadetblue", "plum",  
  "midnightblue", "lawngreen", "darkorange",  
  "lightsteelblue")

clusterCombinedMapping <- piMap
clusterCombinedMapping[,"pch"] <- rep(19, nrow(clusterCombinedMapping))

clusterCombinedMapping[,"color"] <- combinedClusterColors [piEmplid$combined_cluster]



################
## PERCENTILE ##
################

percentileColors <- viridis(10,direction = -1)[c(1:7,10)]
percentileMapping <- piMap

percentileMapping[,"pch"] <- rep(19, nrow(percentileMapping))

percentileMapping[,"color"] <- percentileColors[as.numeric(cut(piEmplid$win.sum_percentile, breaks = seq(0.2,1,by=0.1)))]

#############
## COLLEGE ##
#############

collegeAbbrv <- cbind(
  college = c(sweet16, bigInst, "other"),
  abbrv = c("Arch",
            "Educ",
            "FinArt",
            "Health",
            "Hum",
            "Nurs",
            "Pharm",
            "Science",
            "SocBeh",
            "SocWrk",
            "Bus",
            "Law",
            "Tran",
            "Dent",
            "Med",
            "Engr",
            "EGI",
            "Hunt",
            "SCI",
            "CVRTI",
            "ICSE",
            "CTSI",
            "other"
  ),
  color = c(
    "lightslategray",
    "orange",
    "cyan", 
    "hotpink", 
    "brown", 
    "darkgoldenrod", 
    "gold", 
    "green",
    "navy", 
    "magenta", 
    "olivedrab4", 
    "salmon", 
    "darkgreen",
    "yellowgreen", 
    "red",
    "blue",
    "chocolate", 
    "purple",
    "violet", 
    "khaki",
    "deepskyblue3",
    "chartreuse",
    "darkmagenta"
  ),
  pch = c(
    1,14,15,2,3,4,17,6,5,8,9,10,11,12,13,0,16,7,18, 23, 24, 25, 20  
    
    
  ),
  
  cex = rep(NA, length(c(sweet16, bigInst, "other")) )
)

collegeColors <- setNames(collegeAbbrv[,"color"], collegeAbbrv[,"abbrv"])

```

```{r}

##############################
## ACTIVE PROPOSING PERIODS ##
##############################

minDate <- aggregate(PROPOSAL_UPLOAD_DATE ~ PROPOSAL_PI_EMPLID, data = prepData, FUN =  function(x) {as.Date(min(x))})

maxDate <- aggregate(PROPOSAL_UPLOAD_DATE ~ PROPOSAL_PI_EMPLID, data = prepData, FUN = function(x) {as.Date(max(x))})

activeProposing <- merge(minDate, maxDate, by = "PROPOSAL_PI_EMPLID")
names(activeProposing) <- c("PROPOSAL_PI_EMPLID", "PROPOSAL_UPLOAD_DATE.min", "PROPOSAL_UPLOAD_DATE.max")

activeProposing <- merge(activeProposing, retData[,c("PI_EMPLID", "HIRE_DT", "REHIRE_DT", "TERMINATION_DT")],
               by.x = "PROPOSAL_PI_EMPLID",
               by.y = "PI_EMPLID",
               all.x = TRUE)

```



```{r eval = FALSE}


# Not sure these need their own columns
activeProposing$active <- time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.min, activeProposing$PROPOSAL_UPLOAD_DATE.max), unit = "year")

condition <- is.na(activeProposing$TERMINATION_DT)
activeProposing$inactive_to_date[condition] <- time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max[condition], ymd("2025-05-01")), unit = "year")

activeProposing$inactive_to_term <- time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max, activeProposing$TERMINATION_DT), unit = "year")

# what intervals are interesting?
# hire-to-propose
# re-hire-to-propose
# last propose to term
# active-yet-inactive (yrs since last propose for current headcount)
# productive period (first to last publication)

# I need to differentiate "active"-ly proposing and "current"-ly headcount
# maybe I use "productive"

# I need to use the same logic and count the number of "productive PI's" per week
# And then maybe adjust for those who are current and will probably put out a new proposal

# I'd like to see when the "active" period is during a prof's career.  Are they done at age 50?

# And I can figure out the correct period to use by comparing the min proposing date and the max hire/rehire date that is less than that.

# Before I do that, though, I should compare the various intervals.



```


```{r}

##############################
## PICK HIRE OR REHIRE DATE ##
##############################

# I want:
#  Were they proposing between their hire and re-hire date?  Only before their re-hire date?
#  Were they proposing only after their re-hire date?
#  Were they proposing before AND after their re-hire date?

before_rehire <- activeProposing$PROPOSAL_UPLOAD_DATE.max <= activeProposing$REHIRE_DT

after_rehire <- activeProposing$PROPOSAL_UPLOAD_DATE.min >= activeProposing$REHIRE_DT

before_and_after <- activeProposing$PROPOSAL_UPLOAD_DATE.min <= activeProposing$REHIRE_DT &  activeProposing$PROPOSAL_UPLOAD_DATE.max >= activeProposing$REHIRE_DT
 
# I kinda wanna see a "hire timeline"
# similar to my timeline and timedots, but with hire/rehire/term marked
# and scale it to actual years


#> table(before_rehire)
#before_rehire
#FALSE  TRUE 
#  634   162 
#> table(after_rehire)
#after_rehire
#FALSE  TRUE 
#  191   605 
#> table(before_and_after)
#before_and_after
#FALSE  TRUE 
#  767    29 

# Check
#> table(before_rehire & after_rehire)
#
#FALSE 
#  796 
#> table(before_rehire & before_and_after)
 
#FALSE 
#  796 
#> table(after_rehire & before_and_after)

#FALSE 
#  796 

activeProposing$effective_hire <- activeProposing$HIRE_DT

rehire_condition <- after_rehire & !is.na(after_rehire)
activeProposing$effective_hire[rehire_condition] <- activeProposing$REHIRE_DT[rehire_condition] 

  
```


```{r}

# modified timeline
# I want to modify the timeline to plot against the years
# and include the hire/rehire/termination dates

# a good picture is worth a thousand words.



```


```{r}

###################################
## CALCULATE RETENTION INTERVALS ##
###################################

# library(lubridate)

# This is the initial time between "hire date" and "re-hire date"
retData$initial <- time_length(interval(retData$HIRE_DT, retData$REHIRE_DT), unit = "year")

# This is the time between "re-hire date" and "termination date"
retData$rehire <- time_length(interval(retData$REHIRE_DT, retData$TERMINATION_DT), unit = "year")

# This is the time from initial hire to termination date
retData$hire <- time_length(interval(retData$HIRE_DT, retData$TERMINATION_DT), unit = "year")


```


# EXECUTIVE SUMMARY

All graphics produced in this report used incomplete data, and no conclusions should be drawn.

This incomplete data set shows a decline in the estimated headcount of principal investigators starting in about 2020 due to reduced hires and increased departures.  No investigation or explanation is attempted in this report.

It also shows that Cluster 5 PI's (nick-named "Prolific" for being the workhorses of U research), and the population above the 90th percentile for funds won during a ten year period, are more stable with fewer departure counts than other clusters or percentiles.  This creates a "chicken-or-the-egg" question as to whether their proclivity led to their stability or vice versa.

Upon re-analyzing with complete data, valid conclusions can be drawn.

# SUMMARY

The retention data contains records for `r nrow(retData) |> format(big.mark = ",")` principal investigators, where principal investigators are extracted from the table "osp.d_pi_vw" and are presumably identified according to the definitions and designations found in [Rule R7-200B](https://regulations.utah.edu/research/rules_7/r7-200b.php#a.II).  The definition of a principal investigator and inclusion in this data set is being reviewed.

This data set includes all `r table(retData$PI_EMPLID %in% prepData$PROPOSAL_PI_EMPLID)[2] |> format(big.mark = ",") ` principal investigators who submitted proposals after FY2013 as described in the Grants Exploratory project, and contains an additional `r table(retData$PI_EMPLID %in% prepData$PROPOSAL_PI_EMPLID)[1] |> format(big.mark = ",") ` principal investigators who presumably submitted proposals before 2013.  Although additional information from HR is forthcoming, and the designation of "principal investigator" in OSP data is being reviewed, it may be prudent to exclude the additional PI's from future projects due to incomplete data on their proposal submissions.

The data contains up to three dates per PI:  initial hire date, one re-hire date, and the most recent termination date (if it exists.)  Because not all termination and re-hire dates are included, it is impossible to accurately tabulate head count.  This prevents accurate calculation of metrics that use the headcount as a denominator, such as the turnover rate.  Instead, re-hire dates are ignored and headcount is estimated using the initial hire date.

As well, action reasons (such as an explanation for termination) are not included, making it is impossible to distinguish "voluntary" and "involuntary" separation.

***Dates and intervals:***    
The earliest hire date reaches back to  `r year(min(retData$HIRE_DT, na.rm = TRUE))`, and the earliest termination date is in `r year(min(retData$TERMINATION_DT, na.rm = TRUE))`.  The largest interval between initial hire and rehire date is `r round(max(retData$initial, na.rm = TRUE))` years, and the largest interval between hire date and termination date is `r round(max(retData$hire, na.rm = TRUE))` years.

***Seasonality:***    
The data shows most hire or termination activity happening in the middle of the year around July 1st.

***Apparent population decline overall:***   
Population head count appears to decline from 2020 onwards due to an increase in terminations and a decrease in hiring.  Because re-hires are ignored, head count is roughly estimated.

***Estimated population by college:***
Among the colleges, the count of departures increased dramatically in 2024 at Engineering and Science, and remained stable (though elevated) at the School of Medicine and at the Huntsman Cancer Institute. 

***Estimated population by cluster:***
The description of the clusters is contained in a report titled "Clustering principal investigators without time variables." 

Among the clusters, departure counts among PI's not assigned to a cluster (due to too few proposals) are highest, and lowest in Cluster 5 "Prolific" (the workhorses of research at the U.)   

***Estimated population by percentile:***
A description of the percentiles is yet to be written. Percentiles were originally calculated based on ten years' of performance.  The 90th percentile or higher population has the lowest departure counts and what appears to be the most stable population.  Because the percentiles were calculated based on ten years' of performance, it introduces a chicken-or-egg question:  is this population successful because they are stable, or stable because they are successful?  Or, are highly successful researchers not part of the ten-year percentile because they left after only three years?

To answer this question, percentiles were then re-calculated on an annual basis.  About 40% of the PI's consistently win funds within a five percentile range of themselves in any given year.  However, a very strong alternating pattern was discovered where a PI wins at a high percentile in one year followed by a low percentile in the next year.  This pattern is noted in this report and deferred to examine in a yet-to-be-written report examining annual performance.    








It consisted of a an intial hire date and re-hire or final termination dates as applicable.  Because there was no initial termination date paired with the re-hire date, the re-hire date was ignored.  This means that the headcount was calculated only using the initial hire date.  Because the head count was wrong, metrics like turnover rate that rely on the head count are wrong.


# 1) DESCRIBE THE RETENTION DATA   

### QUERY

VPR.D_PI_EMP_DT_VW as
  SELECT pi."PI_DIM_KEY",    
         pi."PI_EMPLID",    
         pi."PI_FIRST_NAME",    
         pi."PI_MIDDLE_NAME",    
         pi."PI_LAST_NAME",    
         pi."PI_NAME",    
         pi."PI_EMAIL_ADDRESS",    
         pi."PI_PHONE",    
         pi."PI_INDICATOR",    
         pi."IS_PI",    
         pi."PI_LOAD_DATE_TIME",    
         pi."PI_UPDATE_DATE_TIME",    
         emp.hire_dt,    
         emp.rehire_dt,    
         emp.termination_dt
         FROM osp.d_pi_vw pi
         LEFT JOIN uuetl_hr.PS_UU_EMPLOYMENT_VW emp ON pi.pi_emplid = emp.emplid

### DATA SUMMARY

```{r include=TRUE}

skim(retData)

```

### Retention dates

```{r}

# Raw numbers, yearly, individual graphics

plotPar <- par(mfrow = c(3,1), 
               bg = "ivory", 
               fg = "gray20",
               mar = c(2, 4.1, 2, 0.3)
               )

#mar = c(2, 4.1, 1.1, 0.1)) # c(5.1,4.1,4.1,2.1)

table(year(retData$HIRE_DT)) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of hires",
       main = "Hires over time",
       type = "l",
       col = "chocolate4")


table(year(retData$REHIRE_DT)) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of re-hires",
       main = "Re-hires over time",
       type = "b",
       col = "chocolate4")



table(year(retData$TERMINATION_DT)) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of terminations",
       main = "Terminations over time",
       type = "b",
       col = "chocolate4")



par(plotPar)

# maybe a cumulative graphic?
# maybe scaled lines on the same graphic? (Gotta do this one!)

```

### Retention intervals

```{r}

#######################
## DISPLAY INTERVALS ##
#######################

histPar <- par(mfrow = c(3,1), mar = c(2.5, 4.1, 2.6, 0.1)) # c(5.1,4.1,4.1,2.1)

hist(retData$initial,
     main = "Interval in years after hire until rehire",
     cex.main = 1.382,
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "lightseagreen")
legend("topright", legend = paste( format(sum(is.na(retData$initial)), big.mark = ","), "NA values"), bty = "n", text.col = "red", cex = 1.618)

hist(retData$rehire,
     main = "Interval in years after rehire until termination",
     cex.main = 1.382,
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "lightgreen")
legend("topright", legend = paste(format( sum(is.na(retData$rehire)), big.mark=",") , "NA values"), bty = "n", text.col = "red", cex = 1.618)


hist(retData$hire,
     main = "Interval in years after hire until termination",
     cex.main = 1.382,
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "aquamarine")
legend("topright", legend = paste(format( sum(is.na(retData$hire)), big.mark= ","), "NA values"), bty = "n", text.col = "red", cex = 1.618)

par(histPar)

```



### Seasonality

```{r}

# I like this graphic.
# Convert it to three lines for my three date columns.
# Maybe move this after "dates" and before "intervals."

weeklyTerms <- table(week(retData$TERMINATION_DT))
weeklyHires <- table(week(retData$HIRE_DT))
weeklyRehires <- table(week(retData$REHIRE_DT))

yLim <- c(min(c(weeklyTerms, weeklyHires,weeklyRehires), na.rm = TRUE), max(c(weeklyTerms, weeklyHires,weeklyRehires), na.rm = TRUE) )

plotPar <- par(bg = "ivory", fg = "gray20")

plot(weeklyTerms,
     ylim = yLim,
     type = "n",
     ylab = "",
     las = 1,
     xlab = "week of year")

points(weeklyHires,
       type = "l",
       col = "purple")

points(weeklyRehires,
       type = "l",
       col = "orange")

points(weeklyTerms,
       type = "l",
       col = "firebrick")

mtext(side = 3,
      "Most workforce activity happens in Week 26",
      font =2,
      cex = 1.384,
      line = 1)

legend("topleft",
       legend = c("hire","rehire","termination"),
       col = c("purple","orange", "firebrick"),
       pch = 15,
       pt.cex = 2)

par(plotPar)

```


```{r eval=FALSE}

# I decided to use the annual one instead (converted to a line chart)

# Raw numbers, quarterly, individual graphics

plotPar <- par(mfrow = c(3,1), bg = "ivory", fg = "gray20")

table(paste(year(retData$HIRE_DT), quarter(retData$HIRE_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of hires",
       main = "Hires over time",
       col = "chocolate4")


table(paste(year(retData$REHIRE_DT), quarter(retData$REHIRE_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of re-hires",
       main = "Re-hires over time",
       col = "chocolate4")



table(paste(year(retData$TERMINATION_DT), quarter(retData$TERMINATION_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of terminations",
       main = "Terminations over time",
       col = "chocolate4")



par(plotPar)

# maybe a cumulative graphic?
# maybe scaled lines on the same graphic? (Gotta do this one!)

```



# 2) CALCULATE AND COMPARE TURNOVER

### Approximate tabulations of the principal investigator population


```{r}

########################
## CALCULATE TURNOVER ##
########################

calendar <- c("day","week", "month", "quarter", "year")

fullSpan <- lapply(calendar, function(x){
  
  calculateMetrics(calendar = x,
                   minDate = ymd("1960-01-01"),
                   maxDate = today(),
                   data = retData)
  
})
names(fullSpan) <- calendar

midSpan <- lapply(calendar, function(x){
  
  calculateMetrics(calendar = x,
                   minDate = ymd("2013-01-01"),
                   maxDate = today(),
                   data = retData)
  
})
names(midSpan) <- calendar

earlySpan <- lapply(calendar, function(x){
  
  calculateMetrics(calendar = x,
                   minDate = ymd("2000-01-01"),
                   maxDate = ymd("2020-12-31"),
                   data = retData)
  
})
names(earlySpan) <- calendar

lateSpan <- lapply(calendar, function(x){
  
  calculateMetrics(calendar = x,
                   minDate = ymd("2020-01-01"),
                   maxDate = today(),
                   data = retData)
  
})
names(lateSpan) <- calendar

```

```{r}

plotMetrics(
  data = fullSpan[["year"]],
  plotList = c("cumulative","count","delta.count"),
  title_mtext_params = list(text = c("Available data used to approximate the PI population", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1)),
  cumulative_legend_params = list(legend = "full data"),
  delta_legend_params = list(legend = "full data")
)


plotMetrics(
  data = midSpan[["year"]],
  plotList = c("cumulative","count","delta.count"),
      title_mtext_params = list(text = c("Approximate PI population from 2013 onwards", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1)),
    cumulative_legend_params = list(legend = "full data"),
  delta_legend_params = list(legend = "full data")
)

```




```{r eval = FALSE}

# Removing the re-hires
# I don't think there's a point in showing this graphic.

calculateMetrics(calendar = "year",
                 minDate = ymd("2013-01-01"),
                 maxDate = today(),
                 data = retData[is.na(retData$REHIRE_DT),]) |>
  (\(x){
  plotMetrics(
      data = x,
  plotList = c("cumulative","count","delta.count"),
    title_mtext_params = list(text = "Approximate PI Headcount\nrehires removed", line = -1.618),
  cumulative_plot_params = list(mar = c(0,6,3,1))
  )})()


```

```{r eval=FALSE}

########################
## CALCULATE TURNOVER ##
########################

turnover_wk <- calculateTurnover(data = retData, interval = "week")

turnover_qt <- calculateTurnover(data = retData, interval = "quarter")

turnover_yr <- calculateTurnover(data = retData, interval = "year")


```

```{r eval=FALSE}

# delete me sooner rather than later

plotPar <- par(mfrow = c(3,1), 
               bg = "ivory", 
               fg = "gray20",
               mar = c(4, 4.1, 2, 0.3)
               )

plot(turnover_wk$hire,
     cex = 0.3,
     main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_wk$label[ticks+1],
     las = 2)

plot(turnover_qt$hire,
     cex = 0.3,
     main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_qt), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_qt$label[ticks+1],
     las = 2)

plot(turnover_yr$hire,
     cex = 0.3,
     main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_yr), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_yr$label[ticks+1],
     las = 2)



```


```{r eval=FALSE}

# I can delete this
# investigating the "tendrils"

plotPar <- par(mfrow = c(1,1), 
               bg = "ivory", 
               fg = "gray20",
               mar = c(4, 4.1, 4, 0.3)
               )

dateFilter <- turnover_wk$termDT > as.Date("2018-12-01") & turnover_wk$termDT <= as.Date("2020-06-01")

range(scale(turnover_wk$exit[dateFilter]))

plot(scale(turnover_wk$hire[dateFilter]),
     cex = 0.3,
     main = "Count of PI's between hire and termination date \ndoesn't align with exits",
     #main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n",
     type = "l",
     ylim = c(-2,9)
     )

# that's a little clearer what's going on.
# looks like these tendrils simply align with terminations and hires

# So now I'm trying to align them graphically

points(scale(turnover_wk$exit[dateFilter]),
     cex = 0.3,
     # main = "Count of PI's terminated",
     type = "l",
     col="red",
     ylab = "Count of terminated PIs",
     xlab = "",
     xaxt = "n")

legend("topright",
       legend = c("head count", "exit count"),
       lty = 1,
       lwd = 2,
       col = c("sienna","red"),
       cex = 1.3)

#ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
#axis(side = 1,
#     at = ticks,
#     labels = turnover_wk$label[ticks+1],
#     las = 2)

mtext(side = 1, line = 1.33, "This graph shows weekly calculations between 2018-12-01 and 2020-06-01")

mtext(side = 1, line = 2.33, "The misalignment suggests an error in the aggregating formula.")

par(plotPar)



```

  

```{r eval=FALSE}


plotPar <- par(bg = "ivory", fg = "gray20")

plot(turnover_wk$exit,
     cex = 0.3,
     main = "Count of PI's terminated",
     type = "l",
     col="darkorange2",
     ylab = "Count of terminated PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_wk$label[ticks+1],
     las = 2)




```

```{r eval=FALSE}

qt_sc <- turnover_qt[,-(1:2)] |>
  scale()

yr_sc <- turnover_yr[,-(1:2)] |>
  scale()


```


```{r eval=FALSE}

plot(1,
     ylim = c(min(qt_sc),max(qt_sc)),
     xlim = c(0,nrow(qt_sc)),
     type = "n",
     xaxt = "n",
     xlab = "",
     ylab = ""
)

lines(qt_sc[,1], col = "sienna")
lines(qt_sc[,3], col = "darkorange2")

legend("topleft",
       legend = c("Active PIs","Turn-over"),
       col = c("sienna","darkorange2"),
       lty = 1,
       lwd = 1.619)

mtext(side = 3,
      "Quarterly PI head-count and turnover\n(scaled)",
      line = 1.33,
      cex=1.3,
      font = 2)

ticks <- seq(from = 0, to = nrow(turnover_qt), length.out = 9)
axis(side = 1,
     at = ticks,
     las =2,
     labels = turnover_qt[ticks+1 ,"label"])



```

```{r eval=FALSE}

# because the turnover is in error (based on assumptions we know are faulty) then there's not so much point in emphasizing or zooming in on this graphic or scaling it with the headcount.

# but the increasing departure rate is an interesting talking point.

plot(1,
     ylim = c(min(yr_sc),max(yr_sc)),
     xlim = c(0,nrow(yr_sc)),
     type = "n",
     xaxt = "n",
     xlab = "",
     ylab = ""
)

lines(yr_sc[,1], col = "sienna", lwd = 2)
lines(yr_sc[,3], col = "darkorange2")

legend("topleft",
       legend = c("Active PIs","Turn-over"),
       col = c("sienna","darkorange2"),
       lty = 1,
       lwd = 1.619)

mtext(side = 3,
      "Yearly PI head-count and turnover\n(scaled)",
      line = 1.33,
      cex=1.3,
      font = 2)

ticks <- seq(from = 0, to = nrow(turnover_yr), length.out = 9)
axis(side = 1,
     at = ticks,
     las =2,
     labels = turnover_yr[ticks+1 ,"label"])


```


### Approximate tabulations of the principal investigator population by college

```{r}

colleges <- unique(prepData$college)
collegePIs <- lapply(colleges, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$college == x]))
names(collegePIs) <- colleges

collegeMetrics <- lapply(collegePIs, function(x){
  
  calculateMetrics(data=retData[retData$PI_EMPLID %in% x,],
                   minDate = ymd("2013-01-01"),
                   maxDate = today(), 
                     calendar = "year")
  
})


```


```{r eval=FALSE}

colleges <- unique(prepData$college)
collegePIs <- lapply(colleges, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$college == x]))
names(collegePIs) <- colleges

collegeTurnover <- lapply(collegePIs, function(x){
  
  calculateTurnover(data=retData[retData$PI_EMPLID %in% x,] , interval = "year")
  
})

```


```{r eval=FALSE}

# Waiting on better data with fewer assumptions

# Kruskal-wallis

cT <- unlist( lapply(collegeTurnover, function(df) df[["to"]]))

kruskal.test(cT ~ names(cT))

cT.frame <- do.call(rbind, collegeTurnover)
cT.frame$college <- sub("\\..*", "", row.names(cT.frame))

college.kW <- kruskal.test(to ~ college, data = cT.frame)

```


```{r eval=FALSE}

# Do this with the adjusted data,
# or better data if you get it (that doesn't ignore "rehire" date)

plot(1, 
     type = "n", 
     ylim = c(0.,0.3),  #c(-4,4), 
     xlim = c(2013,2026),
     xaxt = "n",
     xlab = "",
     ylab = "turnover")
lapply(collegeTurnover, function(x){
  lines((x[,"to"]), x = as.numeric(x[,"label"]), col = "gray40")
  
})

ticks <- seq(from = 2013, to = 2026, by = 2)
axis(side = 1,
     at = ticks,
     las =2,
     labels = ticks)

legend("topleft", legend = paste("p-value of", round(college.kW$p.value,2)), text.col = "red", bty = "n")

mtext(side = 3,
      text = "Turnover does not vary greatly by college",
      cex = 1.3,
      line= 2,
      font = 2)

mtext(side = 3,
      text = "(according to the Kruskal-Wallis test)",
      cex = 1,
      line = 0.5,
      font = 3)


```


```{r}

#########################
##        PLOT OF      ##
## METRICS PER COLLEGE ##
#########################

# Medicine

plotMetrics(data = collegeMetrics[c("Med")],
            plotList = c("cumulative","count","delta.count"),
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="left"),
            delta_legend_params = list(x="left"),
            featureMap = collegeColors,
            title_mtext_params = list(text = c("Approximate PI population (School of Medicine)", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1))
            )

# Next three

plotMetrics(data = collegeMetrics[c("Hunt","Engr","Science")],
            plotList = c("cumulative","count","delta.count"),
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="left"),
            delta_legend_params = list(x="bottomleft"),
            featureMap = collegeColors,
            title_mtext_params = list(text = c("Approximate PI population (Huntsman, Engr, and Science)", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1))
            )

# Everyone else

plotMetrics(data = collegeMetrics[!names(collegeMetrics) %in% c("Med", "Hunt","Engr","Science")],
            plotList = c("cumulative","count","delta.count"),
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x = "top"),
            metric_legend2_params = list(plot = FALSE),
            delta_legend_params = list(plot = FALSE),
            featureMap = collegeColors,
            title_mtext_params = list(text = c("Approximate PI population (remaining organizations)", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1))
            )

# DOES TERMINATION ALWAYS START AT ZERO? COUNT AND RATE?
# OR JUST FOR THIS DATA SELECTION?

```



### Approximate tabulations of the principal investigator population by cluster

Please see the report "Clustering principal investigators without time variables" for a lengthier description of the clusters. 
The cluster nicknames and percent of total funds requested won (over ten years) are as follows:

  * "Perfect" (Cluster 1) (2% of funds requested won)
  * "Precise" (Cluster 2) (13% of funds requested won)
  * "Pipe dreams" (Cluster 3) (0% of funds requested won)
  * "Plucky" (Cluster 4) (14% of funds requested won)
  * "Prolific" (Cluster 5) (71% of funds requested won)

```{r}

complex_clusters <- levels(prepData$complex_cluster)

complexPIs <- lapply(complex_clusters, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$complex_cluster == x & !is.na(prepData$complex_cluster)]))
names(complexPIs) <- complex_clusters

# add the unassigned PI's, or NA values for prepData$complex_cluster

complexPIs[["unassigned"]] <- unique(prepData$PROPOSAL_PI_EMPLID[is.na(prepData$complex_cluster)])

complexMetrics <- lapply(complexPIs, function(x){
  
  calculateMetrics(data=retData[retData$PI_EMPLID %in% x,],
                    minDate = ymd("2013-01-01"),
                    maxDate = today(), 
                    calendar = "year")
  
})

```

```{r eval=FALSE}

# repeat with better data that doesn't ignore "rehire" date

# Kruskal-wallis

compT.frame <- do.call(rbind, complexTurnover)
compT.frame$complex_cluster <- sub("\\..*", "", row.names(compT.frame))

complex.kW <- kruskal.test(to ~ complex_cluster, data = compT.frame)

```


```{r eval=FALSE}

# re-do this with plotly and the correct cluster colors

plot(1, 
     type = "n", 
     ylim = c(0.,0.1),  #c(-4,4), 
     xlim = c(2013,2026),
     xaxt = "n",
     xlab = "",
     ylab = "turnover")
lapply(complexTurnover, function(x){
  lines((x[,"to"]), x = as.numeric(x[,"label"]), col = "gray40")
  
})

ticks <- seq(from = 2013, to = 2026, by = 2)
axis(side = 1,
     at = ticks,
     las =2,
     labels = ticks)

legend("topleft", legend = paste("p-value of", round(complex.kW$p.value,2)), text.col = "red", bty = "n")

mtext(side = 3,
      text = "Turnover does not vary greatly by cluster",
      cex = 1.3,
      line= 2,
      font = 2)

mtext(side = 3,
      text = "(according to the Kruskal-Wallis test)",
      cex = 1,
      line = 0.5,
      font = 3)


```

```{r eval=FALSE}

  p <- plot_ly(
    type = "scatter",
    mode = "lines",
    xaxis = list(title = "", range = c(2013,2026)),
    yaxis = list(title = "Departure rate", range = c(0,0.1))
  )
  
for(x in complexMetrics){
    
     p <- add_lines(p, 
                   x = as.numeric(x[, "adjDate"]),
                   y = 100*x[, "termRate"],
                   line = list(color = "gray40"),
                   showlegend = FALSE)
    
  }

# Needs a title
# Needs cluster colors
# Without reference to the cluster, it's pretty pointless
# This really doesn't need to be a "plotly" graphic.
# I can do this with the correct colors and a good legend that has the cluster nick-name.



```

```{r}

#########################
##        PLOT OF      ##
## METRICS PER CLUSTER ##
#########################

plotMetrics(data = complexMetrics,
            plotList = c("cumulative","count","delta.count"),
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="topleft"),
            delta_legend_params = list(plot=FALSE),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = c("Approximate PI population by cluster", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1))
            )


#########################
##        PLOT OF      ##
## METRICS PER UNASSIGNED CLUSTER ##
#########################

plotMetrics(data = complexMetrics["unassigned"],
            plotList = c("cumulative","count","delta.count"),
            cumulative_points_params = list(lwd=3),
            term_points_params = list(type = "l", lwd=3),
            delta_points_params = list(lwd=3),
            metric_legend_params = list(x="topleft"),
            delta_legend_params = list(plot=FALSE),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = c("Approximate PI population (unassigned cluster)", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1))
            )

#########################
##        PLOT OF      ##
## METRICS PER 2 and 4 CLUSTER ##
#########################

plotMetrics(data = complexMetrics[c(2,4)],
            plotList = c("cumulative","count","delta.count"),            
            metric_legend_params = list(x="topright"),
            metric_legend2_params = list(x="topleft"),
            delta_legend_params = list(x="topleft"),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = c("Approximate PI population (clusters 2 and 4)", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1)),
  cumulative_points_params = list(lwd=3),
            term_points_params = list(type = "l", lwd=3),
            delta_points_params = list(lwd=3)
            )


#########################
##        PLOT OF      ##
## METRICS PER 1 and 3 CLUSTER ##
#########################

plotMetrics(data = complexMetrics[c(1,3)],
            plotList = c("cumulative","count","delta.count"),            
            metric_legend_params = list(x="topright"),
            metric_legend2_params = list(x="topleft"),
            delta_legend_params = list(x="topleft"),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = c("Approximate PI population (clusters 1 and 3)", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1)),
  cumulative_points_params = list(lwd=3),
            term_points_params = list(type = "l", lwd=3),
            delta_points_params = list(lwd=3)
            )


#########################
##        PLOT OF      ##
## METRICS PER 5 CLUSTER ##
#########################

plotMetrics(data = complexMetrics[5],
            plotList = c("cumulative","count","delta.count"),            
            metric_legend_params = list(x="topright"),
            metric_legend2_params = list(x="topleft"),
            delta_legend_params = list(x="topleft"),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = c("Approximate PI population (cluster 5)", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1)),
  cumulative_points_params = list(lwd=3),
            term_points_params = list(type = "l", lwd=3),
            delta_points_params = list(lwd=3)
            )

```


### Approximate tabulations of the principal investigator population by percentiles.

Percentiles are calculated based on the ten year sum of funds requested won per PI.  A lengthier description is yet to be written.    



```{r}

###########################
## CALCLUATE PERCENTILES ##
###########################

# I'm writing over my method for the complex_cluster.
# So you may be looking at a mix of new and old code here

# now I am using piClusters[[2]] instead of piEmplid, as it has -all- PI's without the filtering based on count

piClusters[[2]][,"win.sum_tile"] <- cut(piClusters[[2]][,"win.sum_percentile"], breaks = c(0,seq(0.2,1,by=0.1)), include.lowest = TRUE )

piPercentiles <- levels(piClusters[[2]][,"win.sum_tile"])

pisPerTile <- lapply(piPercentiles, function(x) {
  filter <- piClusters[[2]][,"win.sum_tile"] == x
  unique(piClusters[[2]][filter,"emplid"])
  
  })

names(pisPerTile) <- piPercentiles

# Not needed as I am using -all- PI's to calcualte the percentile
# add the unassigned PI's, or NA values for prepData$complex_cluster

# pisPerTile[["unassigned"]] <- unique(prepData$PROPOSAL_PI_EMPLID[!(prepData$PROPOSAL_PI_EMPLID %in% unlist(pisPerTile))])

tileMetrics <- lapply(pisPerTile, function(x){
  
  calculateMetrics(data=retData[retData$PI_EMPLID %in% x,],
                    minDate = ymd("2013-01-01"),
                    maxDate = today(), 
                    calendar = "year")
  
})

```


```{r}

######################
## PLOT PERCENTILES ##
######################

tileColors <- c("burlywood1", percentileColors)
names(tileColors) <- names(tileMetrics)


plotMetrics(data = tileMetrics,
            plotList = c("cumulative","count","delta.count"),            
            metric_legend_params = list(x="topright"),
            metric_legend2_params = list(x="topleft"),
            delta_legend_params = list(x="topleft"),
            featureMap = tileColors,
            title_mtext_params = list(text = c("Approximate PI population by percentiles", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1)),
  cumulative_points_params = list(lwd=3),
            term_points_params = list(type = "l", lwd=3),
            delta_points_params = list(lwd=3)
            )

```


```{r eval=FALSE}

# I decided not to do a deep dive and show these variations

plotMetrics(data = tileMetrics[(names(tileMetrics) %in% c("(0.7,0.8]", "(0.8,0.9]", "(0.9,1]"))],
            plotList = c("cumulative","count","delta.count"),            
            metric_legend_params = list(x="topright"),
            metric_legend2_params = list(x="topleft"),
            delta_legend_params = list(x="topleft"),
            featureMap = tileColors,
            title_mtext_params = list(text = c("Approximate PI population (greater than 70th percentile)", "rehire dates ignored"), line = c(-0.8, -2.5), cex = c(1.618,1.3), font = c(2,3), side = c(3,3) ),
  cumulative_plot_params = list(mar = c(0,6,3,1)),
  cumulative_points_params = list(lwd=3),
            term_points_params = list(type = "l", lwd=3),
            delta_points_params = list(lwd=3)
            )



plotMetrics(tileMetrics[(names(tileMetrics) %in% c("(0.7,0.8]", "(0.8,0.9]", "(0.9,1]"))],
            plotList = c("cumulative","count","delta.count"),
            featureMap = tileColors
            )

plotMetrics(tileMetrics[(names(tileMetrics) %in% c("(0.4,0.5]", "(0.5,0.6]", "(0.6,0.7]"))],
            plotList = c("cumulative","count","delta.count"),
            featureMap = tileColors
            )

plotMetrics(tileMetrics[(names(tileMetrics) %in% c("[0,0.2]",   "(0.2,0.3]", "(0.3,0.4]"))],
            plotList = c("cumulative","count","delta.count"),
            featureMap = tileColors
            )

plotMetrics(tileMetrics[(names(tileMetrics) %in% c("(0.2,0.3]", "(0.3,0.4]"))],
            plotList = c("cumulative","count","delta.count"),
            featureMap = tileColors
            )


plotMetrics(tileMetrics[(names(tileMetrics) %in% c("[0,0.2]"))],
            plotList = c("cumulative","count","delta.count"),
            featureMap = tileColors,
            cumulative_points_params = list(lwd = 4, col = tileColors["[0,0.2]"]),
            delta_points_params = list(lwd = 4, col = tileColors["[0,0.2]"])
            )

# cumulative_plot_params = list(mar = c(0,6,3,1))




```




```{r}

###############################
## ANNUAL AMOUNT WON BY TILE ##
###############################

popper <- merge(prepData, piClusters[[2]][,c("emplid", "win.sum_percentile", "win.sum_tile")], by.x = "PROPOSAL_PI_EMPLID", by.y = "emplid" )

# I've probably already created this graphic in my library
# I could use the "trends" one

# looks like I want 

# calculateWinRates |> extractColumn |> createFrame |> extractTrendClusters |> plotTrends

tileRates <- calculateWinRates(data = popper,
                  targetColumn = "PROPOSAL_TOTAL_SPONSOR_BUDGET",
                  categoryColumn = "win.sum_tile")



tile_by_year <- lapply(levels(popper$win.sum_tile), function(tile){
  
  theCut <- popper[popper$win.sum_tile == tile,]
  theAgg <- calculateWinRates(data = theCut, categoryColumn = "upload_fiscal_year", functionList = list(mean = mean, median = median)) |>
    (\(x){ return(x$summary[order(as.numeric(row.names(x$summary)), decreasing = FALSE),]) })()
  
  return(theAgg)  
  
})
names(tile_by_year) <- levels(popper$win.sum_tile)


tileMap <- cbind(college = levels(popper$win.sum_tile),
                 abbrv = levels(popper$win.sum_tile),
                 color = tileColors,
                 pch = 0:8,
                 cex = NA
                 )

```


```{r eval = FALSE}

############################################
## PUT IN REPORT DEDICATED TO PERCENTILES ##
############################################

plotWinRates(tileRates[[1]], agg = "sum")  # SHOW THIS GRAPH IN A REPORT DEDICATED TO PERCENTILES

extractColumn(tile_by_year, "win.sum", drop = FALSE) |>
  (\(x){ 
  suppressWarnings(createFrame(x)) })() |>
#    (\(x){data.frame(x[,1], scale(x[,-1]))})() |> # scale
#  (\(x){x[x == 0] <- NA; # log
#  data.frame(x[,1], log(x[,-1]));
#  })() |>
  extractTrendClusters(k=3, type = "slope", dist_params = list(method = "maximum") ,hclust_params =list(method = "ward.D2")) |>
  plotTrends(
             detailMapping = tileMap,
             plot_order = "slope.increasing",
             bottom_axis_params = list(outer = FALSE, line = -3.5, tick = FALSE), 
             right_axis_params = list(line = -3, tick = FALSE),
             plot_params = list(oma = c(1,0,3,1), mar = c(0,7,0,0)),
             mtext_params = list(text = ""),
             legend_params = list(cex=1.5, inset = c(-0.09,0), text.font = 2),
             main_params=list(text = "Funds requested won per tile", cex = 1.5))

# oh, I get it 
# o.k.

# really close to what I want
# It's just not quite what I want
# but it's really close


extractColumn(tile_by_year, "win.sum", drop = FALSE) |>
  (\(x){ 
  suppressWarnings(createFrame(x)) })() |>
    (\(x){
      keepNames <- names(x)
      scaled <- data.frame(x[,1], scale(x[,-1]))
      names(scaled) <- keepNames
      return(scaled)
      
      })() |> # scale
#  (\(x){x[x == 0] <- NA; # log
#  data.frame(x[,1], log(x[,-1]));
#  })() |>
  extractTrendClusters(k=3, type = "slope", dist_params = list(method = "maximum") ,hclust_params =list(method = "ward.D2")) |>
  plotTrends(
             detailMapping = tileMap,
             plot_order = "slope.increasing",
             bottom_axis_params = list(outer = FALSE, line = -3.5, tick = FALSE), 
             right_axis_params = list(line = -3, tick = FALSE),
             plot_params = list(oma = c(1,0,3,1), mar = c(0,7,0,0)),
             mtext_params = list(text = ""),
             legend_params = list(cex=1.5, inset = c(-0.09,0), text.font = 2),
             main_params=list(text = "Funds requested won per tile", cex = 1.5))

# also very interesting
# but not quite what I want

# I want one graphic and one line per tile


tile_by_year_win.sum <- extractColumn(tile_by_year, "win.sum", drop = FALSE) |>
  (\(x){ 
  suppressWarnings(createFrame(x)) })()


plot(x = max(tile_by_year_win.sum[,-1]),
     type = "n",
     ylim = range(tile_by_year_win.sum[,-1]),
     xlim = c(1,nrow(tile_by_year_win.sum)),
     xaxt = "n"
     )

invisible(
lapply(colnames(tile_by_year_win.sum[,-1]), function(tile){
  points(tile_by_year_win.sum[,tile],
         type = "l",
         col = tileColors[tile]
         )
  
})
)

# wow, they are really pulling it in at the top!

# I should do a second graph that is the bottom two for scaling purpose

# I think I'm getting close to completing this as it is, including my add'l questions

# That is, something like, I'll re-name this as "Retention Exploratory Data Analysis 'Partial'" or something like that.

# So I want to graphically clean this up a bit
# Do two graphs, following my golden ratio rule
# bottom plot excludes the top two lines

# I should probably still calculate a year-by-year percentile
# and see how often a PI changes categories


```


```{r}

######################################
## PERCENTILE BY YEAR PLOT FUNCTION ##
######################################

plotAnnualPercentiles <- function(data, sequence = NA, lineColor = NA, rangeSpan = NA){
  
  # Create an empty plot
  
  plot(x= 1,
       type = "n",
       ylim = c(0.3,1),
       xlim = c(1,10),
       las = 1,
       ylab = "",
       xlab = "",
       xaxt = "n"
  )
  
  if(is.na(sequence[1])){
  theSequence <- seq(0,0.7, by = 0.05)
  } else {theSequence <- sequence}
  
  if(is.na(lineColor[1])){
  lineColor <- viridis::inferno(length(theSequence), direction = -1) 
  }
  
  if(is.na(rangeSpan)){
    rangeSpan <- 0.05 
  }
  
  # Plot the lines
  
  invisible(
    lapply(theSequence, function(range_value){ 
      
      filter <- data$range > range_value &  data$range <= range_value + rangeSpan
      
      invisible(
        lapply(data[filter,"emplid"], function(pi){
          
          points(as.numeric(data[data$emplid == pi,as.character(2014:2023)]),
                 type = "l",
                 lwd = 0.2,
                 col = lineColor[which(theSequence == range_value)]
          )
          
        })
      )
      
    })
  )
    
  # Axis and texts
  
  axis(side = 1, at = 1:10, labels = 2014:2023)
  mtext(side = 2, "percentile per PI", line = 3)
  mtext(side = 3, text = "Annual percentile per PI", font = 2, cex = 1.619, line = 2)
  
}



```

```{r}

######################## 
## PERCENTILE BY YEAR ##
########################

# This will take a little bit of logic

# first I filter by year
# then I aggregate by pi
# then I calculate percentile

pi_by_year <- lapply(unique(prepData$upload_fiscal_year)[order(unique(prepData$upload_fiscal_year))], function(fyear){
  
  theCut <- prepData[prepData$upload_fiscal_year == fyear,]
  theAgg <- calculateWinRates(data = theCut,
                              categoryColumn = "PROPOSAL_PI_EMPLID",
                              functionList = list(mean = mean, median = median)) |>
    (\(x){ return(x$summary[order(as.numeric(row.names(x$summary)), decreasing = FALSE),]) })()
  
  return(theAgg)
})
names(pi_by_year) <- unique(prepData$upload_fiscal_year)[order(unique(prepData$upload_fiscal_year))]


# Functions
# piEmplid$win.sum_prop <- proportions(piEmplid$win.sum)
# piEmplid$win.sum_rank <- rank(-piEmplid$win.sum,na.last = "keep", ties.method = "min")
# ecdf_fun <- ecdf(piEmplid$win.sum)
# piEmplid$win.sum_percentile <- ecdf_fun(piEmplid$win.sum)


pi_by_year <- lapply(pi_by_year, function(fyear){
  
  fyear[,"win.sum_prop"] <- proportions(fyear[,"win.sum"])
  fyear[,"win.sum_rank"] <- rank(-fyear[,"win.sum"], na.last = "keep", ties.method = "min")
  ecdf_fun <- ecdf(fyear[,"win.sum"])
  fyear[,"win.sum_percentile"] <- ecdf_fun(fyear[,"win.sum"])
  
  return(fyear)
  
}) 

# now I want to see the PI's that change percentiles from year to year

pi_annual_percentile <- extractColumn(pi_by_year, "win.sum_percentile", drop = FALSE) |>
  (\(x){ 
  suppressWarnings(createFrame(x)) })()
names(pi_annual_percentile)[names(pi_annual_percentile) %in% "year"] <- "emplid"

pi_annual_percentile$range <- apply(pi_annual_percentile[,-1], 1, function(x){diff(range(x, na.rm = TRUE))})        

# let's plot this

hPlot <- hist(pi_annual_percentile$range, plot = FALSE)

theBar <- barplot(hPlot$counts/sum(hPlot$counts),
        las = 2,
        names.arg = hPlot$breaks[-1])

rect(xleft = par("usr")[1],
     ybottom = par("usr")[3],
     xright = par("usr")[2],
     ytop = par("usr")[4],
     col = "grey95"
     )

grid(ny = NULL, nx = NA, lwd =3, col = "grey80")

#barplot(theBar, ann = FALSE, add = TRUE)

barplot(hPlot$counts/sum(hPlot$counts),
        las = 2,
        col = "plum3",
        # names.arg = hPlot$breaks[-1],
        plot = TRUE,
        ann = FALSE,
        add = TRUE)

mtext(side = 3, text = "Span between min and max percentile", font = 2, cex = 1.619, line = 2)

mtext(side = 3, text = "per PI over ten years", font = 3, cex = 1.33, line = 0.8)

mtext(side = 1, text = "Span between min and max percentile", line = 3)

mtext(side = 2, text = "Proportion of PI's", line = 3)

```


```{r eval = FALSE}

# Developing year by year plots

# now let's see some of these dramatic ones
# and then let's compare to the ten yr categories

plot(x= 1,
     type = "n",
     ylim = c(0,1),
     xlim = c(1,10))

filter <- pi_annual_percentile$range > 0.6 &  pi_annual_percentile$range <= 0.7
invisible(
lapply(pi_annual_percentile[filter,"emplid"], function(pi){
  
  points(as.numeric(pi_annual_percentile[pi_annual_percentile$emplid == pi,as.character(2014:2023)]),
         type = "l",
         lwd = 0.2,
         col = "red")
  
})
)

# since this is exploratory data analysis, let's show it.
  
plot(x= 1,
     type = "n",
     ylim = c(0.3,1),
     xlim = c(1,10),
     las = 1,
     ylab = "",
     xlab = "",
     xaxt = "n"
     )

theSequence <- seq(0,0.7, by = 0.05)

invisible(
lapply(theSequence, function(range_value){ 

filter <- pi_annual_percentile$range > range_value &  pi_annual_percentile$range <= range_value + 0.05

invisible(
lapply(pi_annual_percentile[filter,"emplid"], function(pi){
  
  points(as.numeric(pi_annual_percentile[pi_annual_percentile$emplid == pi,as.character(2014:2023)]),
         type = "l",
         lwd = 0.2,
         col = viridis::inferno(length(theSequence), direction = -1)[which(theSequence == range_value)]
         )
  
})
)

})
)

axis(side = 1, at = 1:10, labels = 2014:2023)

mtext(side = 2, "percentile per PI", line = 3)
mtext(side = 3, text = "Annual percentile per PI", font = 2, cex = 1.619, line = 2)


# Let's show low variation, mid-variation, and hi-variation
# which means I'm creating a function.


```

```{r}

theSequence <- seq(0, 0.7, 0.05)

plotAnnualPercentiles(data = pi_annual_percentile)
mtext(side = 3, text = "All PI's", line = 1)


plotAnnualPercentiles(data = pi_annual_percentile, sequence = c(0.0,0.05),
                      lineColor = c("plum4"))
mtext(side = 3, text = "Low variation", line = 1)

plotAnnualPercentiles(data = pi_annual_percentile, sequence = c(0.25,0.35), lineColor = viridis::inferno(length(theSequence), direction = -1)[vapply(seq(from = 0.25, to = 0.35, by = 0.05), function(val) which.min(abs(seq(0, 0.7, 0.05) - val)), integer(1))]
                 )
mtext(side = 3, text = "Medium variation", line = 1)

plotAnnualPercentiles(data = pi_annual_percentile, sequence = c(0.4,0.6),
                      lineColor = viridis::inferno(length(theSequence), direction = -1)[vapply(seq(from = 0.4, to = 0.6, by = 0.05), function(val) which.min(abs(seq(0, 0.7, 0.05) - val)), integer(1))])
mtext(side = 3, text = "High variation", line = 1)

# Now, it would be nice to see a plot of these per cluster
# And, to see not just the percentile but whatever y-axis I want
# More work on this function would be nice


```


```{r eval=FALSE}

# Copying and pasting from other places

# FISCAL YEAR -- BY COLLEGE (loaded in prepScript)

college_by_year <- lapply(unique(prepData$college), function(college){
  
  theCut <- prepData[prepData$college == college,]
  theAgg <- calculateWinRates(data = theCut, categoryColumn = "upload_fiscal_year", functionList = list(mean = mean, median = median)) |>
    (\(x){ return(x$summary[order(as.numeric(row.names(x$summary)), decreasing = FALSE),]) })()
  
  return(theAgg)  
  
})
names(college_by_year) <- unique(prepData$college)

extractColumn(college_by_year, "win.sum", drop = FALSE) |>
  createFrame() |>
    (\(x){data.frame(x[,1], scale(x[,-1]))})() |> # scale
#  (\(x){x[x == 0] <- NA; # log
#  data.frame(x[,1], log(x[,-1]));
#  })() |>
  extractTrendClusters(k=3, type = "slope", dist_params = list(method = "maximum") ,hclust_params =list(method = "ward.D2")) |>
  plotTrends(detailMapping = collegeAbbrv,
             plot_order = "slope.increasing",
             bottom_axis_params = list(outer = FALSE, line = -3.5, tick = FALSE), 
             right_axis_params = list(line = -3, tick = FALSE),
             plot_params = list(oma = c(1,0,3,1), mar = c(0,7,0,0)),
             mtext_params = list(text = ""),
             legend_params = list(cex=1.5, inset = c(-0.09,0), text.font = 2),
             main_params=list(text = "Funds requested won per college", cex = 1.5))

```


```{r eval=FALSE}

###################################
## DURATIONS USING COMBINED DATA ##
###################################


histPar <- par(mfrow = c(3,1),
               mar = c(2,3,3,0),
               bg = "ivory",
               fg = "gray10")

minTwoCondition <- activeProposing$PROPOSAL_PI_EMPLID %in% row.names(fullEmplid)[filterTwoCount]
time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.min[minTwoCondition], activeProposing$PROPOSAL_UPLOAD_DATE.max[minTwoCondition]), unit = "year") |>
  hist(main = "Active proposing duration\n(from first to last proposal date in years)\n(minimum of two proposals)",
               col = "skyblue",
       ylab = "count of PIs")

time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max, activeProposing$TERMINATION_DT), unit = "year") |>
  hist(main = "Inactive period from last proposal to termination (years)",
               col = "deepskyblue",
       ylab = "count of PIs")

condition <- is.na(activeProposing$TERMINATION_DT)
 time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max[condition], ymd("2025-05-01")), unit = "year") |>
   hist(main = "Inactive period from last proposal to 30 April 2025 \n(employed as of data cut-off of 30 April 2025)",
               col = "dodgerblue",
       ylab = "count of PIs")

# Maybe active needs to be filtered to PI's with at least two proposals? DONE
 
 
# For people active in the hire date -- how long from hire until submission?
# For people active in the rehire date -- how long from re-hire until submission?
# For all of them -- how long from last submission until termination?

# Hire until first submission

# I can use filters here or I can create an "effective hire date" 
 
time_length(interval(activeProposing$effective_hire, activeProposing$PROPOSAL_UPLOAD_DATE.min), unit = "year") |> # max() # 50 yrs!
  hist(main = "Period from effective hire to first proposal")

# something is still wrong

time_length(interval(activeProposing$effective_hire, activeProposing$PROPOSAL_UPLOAD_DATE.min), unit = "year") |>
  (\(x){which(x == max(x))})()

# the problem is that I don't have good proposal data until 2013.
# so I should truncate this to people hired after 2013

# make this a precise date, the minimum in the prepData
hire2013 <- year(activeProposing$effective_hire) >= 2013
time_length(interval(activeProposing$effective_hire[hire2013], activeProposing$PROPOSAL_UPLOAD_DATE.min[hire2013]), unit = "year") |> # max() # 50 yrs!
  hist(main = "Period from effective hire to first proposal\n(for hires after 2013)")

# there we go, that's a much better graphic


```





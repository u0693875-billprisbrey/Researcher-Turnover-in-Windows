---
title: "Retention Exploratory Data Analysis"
author: "Bill Prisbrey"
date: "2025-04-25"
output: html_document
---



```{r include=FALSE}

# Notes for author

# More thoughts:  
#  - Kruskal wallis is a nice general purpose first-look test, but I should probably find something more appropriate.
#  - Digging into how the intervals were aggregated should be informative (am I sure I'm doing it right?)


# Thoughts:

# - Re-name this as "exploratory data analysis" and summarize the new data view.  "Skimr" and a couple of histograms.
# - I'll probably uncover some data inconsistencies.
# - Use my new "activePI" function to calculate the number of active PI's every week.
# - Create a dataframe that is week-by-week active PI's
# - Use prepData to align publishing periods with hire or re-hire period EVENTUALLY
# - Lack of an initial termination date could be problematic

```


**PURPOSE:**  The purpose of this document is a "quick-and-dirty" or "back-of-the-envelope" exploration.  It briefly describes the retention data and superficially calculate and compare principal investigator turnover.  It will be used to determine if this project is worth pursuing and guide further data collection and transformation steps.   

**OBJECTIVES:**   

  1.  Describe the retention data.
  2.  Calculate and compare turnover    
      a.  By colleges     
      b.  By departments    
      c.  By PI clusters    
      d.  By percentiles    
  2.  Determine if there are differences and if they merit continuation of the project.         
  
  
```{r include = FALSE}

knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, error=FALSE, fig.height=7, fig.width=10)

# adjust graphic parameters

oldPar <- par(cex.main = 3,
    cex.lab = 3,
    cex.axis = 2,
    mar = c(5.1,4.1,4.1,2.1) # default is c(5.1,4.1,4.1,2.1)
    )

```

```{r}

###########
## QUERY ##
###########

# Obtain retention data

keyring::keyring_unlock(keyring = "BIPR", password = "Excelsior!")

library(DBI)
con.ds <- DBI::dbConnect(odbc::odbc(), Driver = "oracle", Host = "ocm-campus01.it.utah.edu", 
                         SVC = keyring::key_list(keyring = "BIPR")[1, 1], UID = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                    2], PWD = keyring::key_get(keyring = "BIPR", service = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                                                                                                               1]), Port = 2080)
retentionQuery <- "
SELECT *
FROM VPR.D_PI_EMP_DT_VW EMP_DATES
"

retData <- dbGetQuery(con.ds,
                      retentionQuery)


DBI::dbDisconnect(con.ds)




```


```{r}

##########
## LOAD ##
##########

# PREP SCRIPT

source(here::here("Prep scripts","Adjusting prepData and loading things.R"))


# PER PI

piClusters <- lapply(list.files(here::here("Robjects", "Clustering PIs"), full.names = TRUE), readRDS)

###########
## MERGE ## 
###########

piEmplid <- Reduce(function(x, y) {
  merged <- merge(x, y, by = "emplid", all = FALSE)
  merged <- merged[, !duplicated(sub("\\.x$|\\.y$", "", names(merged)))]  # Remove duplicate columns
  
  # Rename columns to remove ".x"
  names(merged) <- sub("\\.x$", "", names(merged))
  
  merged
}, piClusters)
# piEmplid <- Reduce(function(x, y) merge(x, y, by = "emplid", all = FALSE), piClusters)
# piEmplid <- do.call(merge, piClusters)



prepData <- merge(prepData, piEmplid[,c("emplid","complex_cluster","rate_cluster")], by.x =  "PROPOSAL_PI_EMPLID", by.y = "emplid", all.x = TRUE)

##########
## PREP ##
##########

piEmplid$combined_cluster <-  factor(paste(piEmplid$complex_cluster, piEmplid$rate_cluster, sep = ", "))

prepData$combined_cluster <- factor(paste(prepData$complex_cluster, prepData$rate_cluster, sep = ", "))

###############
## LIBRARIES ##
###############

library(viridis)
library(pheatmap)

# I'll probably want my per-cluster wins as well

# I am going to want to bring in the colors

filterThreeCount <- piEmplid$count.total > 3

piMap <- data.frame(college = row.names(piEmplid), abbrv = row.names(piEmplid), color = NA, pch = 19, cex = 0.7 )


```



```{r}
             
# Manage colors

#############
## COMPLEX ##
#############

complexClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
                            "firebrick", "darkslategray", "chartreuse",  
                            "slateblue", "darkkhaki", "coral")

clusterComplexMapping <- piMap
clusterComplexMapping[,"pch"] <- rep(19, nrow(clusterComplexMapping))

clusterComplexMapping[,"color"] <- complexClusterColors [piEmplid$complex_cluster]

# clusterComplexMapping[,"color"] <- complexClusterColors[complexHCPC$data.clust$clust[match(clusterComplexMapping[,"college"], row.names(complexHCPC$data.clust))] ]

##############
## COMBINED ##
##############

combinedClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
  "firebrick", "darkslategray", "chartreuse",  
  "slateblue", "darkkhaki", "coral",  
  "mediumorchid", "dodgerblue", "tomato",  
  "orchid", "darkseagreen", "sienna",  
  "royalblue", "indianred", "seagreen",  
  "peru", "cadetblue", "plum",  
  "midnightblue", "lawngreen", "darkorange",  
  "lightsteelblue")

clusterCombinedMapping <- piMap
clusterCombinedMapping[,"pch"] <- rep(19, nrow(clusterCombinedMapping))

clusterCombinedMapping[,"color"] <- combinedClusterColors [piEmplid$combined_cluster]



################
## PERCENTILE ##
################

percentileColors <- viridis(10,direction = -1)[c(1:7,10)]
percentileMapping <- piMap

percentileMapping[,"pch"] <- rep(19, nrow(percentileMapping))

percentileMapping[,"color"] <- percentileColors[as.numeric(cut(piEmplid$win.sum_percentile, breaks = seq(0.2,1,by=0.1)))]

```

# DURATIONS

```{r}

#########################
## CALCULATE INTERVALS ##
#########################

library(lubridate)

# This is the initial time between "hire date" and "re-hire date"
retData$initial <- time_length(interval(retData$HIRE_DT, retData$REHIRE_DT), unit = "year")

# This is the time between "re-hire date" and "termination date"
retData$rehire <- time_length(interval(retData$REHIRE_DT, retData$TERMINATION_DT), unit = "year")

# This is the time from initial hire to termination date
retData$hire <- time_length(interval(retData$HIRE_DT, retData$TERMINATION_DT), unit = "year")


```

```{r}

#######################
## DISPLAY INTERVALS ##
#######################

histPar <- par(mfrow = c(3,1), mar = c(2, 4.1, 1.1, 0.1)) # c(5.1,4.1,4.1,2.1)

hist(retData$initial,
     main = "Duration in years after hire until rehire",
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "lightgreen")
legend("topright", legend = paste( sum(is.na(retData$initial)), "NA values"), bty = "n", text.col = "red")

hist(retData$rehire,
     main = "Duration in years after rehire until termination",
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "seagreen")
legend("topright", legend = paste( sum(is.na(retData$rehire)), "NA values"), bty = "n", text.col = "red")


hist(retData$hire,
     main = "Duration in years after hire until termination",
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "darkgreen")
legend("topright", legend = paste( sum(is.na(retData$hire)), "NA values"), bty = "n", text.col = "red")

par(histPar)

```

Duration thoughts:    

  - The lack of a termination date before the re-hire date introduces guess-work.   
  - Some researchers are apparently hired as students and re-hired later in their career.    
  - Some researchers are apparently hired in retirement after their career. 
  - These durations need to be aligned with proposal submission dates.    
  - This shows that we currently have 2,994 active principal investigators.   

# TERMINATION DATES

```{r}

plotPar <- par(bg = "ivory", fg = "gray20")
table(week(retData$TERMINATION_DT)) |>
  plot(xlab = "week of year",
       ylab = "Count of terminations per week",
       main = "PIs are mostly terminated around June 30th")


```

```{r}


table(paste(year(retData$TERMINATION_DT), week(retData$TERMINATION_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of terminations",
       main = "Terminations over time",
       col = "chocolate4")

# par(plotPar)

```

# ACTIVE PRINCIPAL INVESTIGATORS


```{r}

########################
## CALCULATE TURNOVER ##
########################

turnover_wk <- calculateTurnover(data = retData, interval = "week")

turnover_qt <- calculateTurnover(data = retData, interval = "quarter")

turnover_yr <- calculateTurnover(data = retData, interval = "year")


```

```{r}

plotPar <- par(bg = "ivory", fg = "gray20")

plot(turnover_wk$hire,
     cex = 0.3,
     main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_wk$label[ticks+1],
     las = 2)

```

Discussion points:    

  - Some aspects of this graph appear to be mis-aligned due to how counts per interval were aggregated:
    - Axis labels  
    - Points not along the main curve   
    - This needs to be investigated   
  - The general pattern of an increasing count of PI's that peaked around the year 2020 and declined since needs to be confirmed    
  - Because the total money requested won has increased, this would mean the average per PI has increased.  This could be one double-check. 
  
# TURNOVER

```{r}


plotPar <- par(bg = "ivory", fg = "gray20")

plot(turnover_wk$exit,
     cex = 0.3,
     main = "Count of PI's terminated",
     type = "l",
     col="darkorange2",
     ylab = "Count of terminated PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_wk$label[ticks+1],
     las = 2)


```

```{r}

qt_sc <- turnover_qt[,-(1:2)] |>
  scale()

yr_sc <- turnover_yr[,-(1:2)] |>
  scale()


```


```{r}

plot(1,
     ylim = c(min(qt_sc),max(qt_sc)),
     xlim = c(0,nrow(qt_sc)),
     type = "n",
     xaxt = "n",
     xlab = "",
     ylab = ""
)

lines(qt_sc[,1], col = "sienna")
lines(qt_sc[,3], col = "darkorange2")

legend("topleft",
       legend = c("Active PIs","Turn-over"),
       col = c("sienna","darkorange2"),
       lty = 1,
       lwd = 1.619)

mtext(side = 3,
      "Quarterly PI head-count and turnover\n(scaled)",
      line = 1.33,
      cex=1.3,
      font = 2)

ticks <- seq(from = 0, to = nrow(turnover_qt), length.out = 9)
axis(side = 1,
     at = ticks,
     las =2,
     labels = turnover_qt[ticks+1 ,"label"])



```

```{r}

plot(1,
     ylim = c(min(yr_sc),max(yr_sc)),
     xlim = c(0,nrow(yr_sc)),
     type = "n",
     xaxt = "n",
     xlab = "",
     ylab = ""
)

lines(yr_sc[,1], col = "sienna", lwd = 2)
lines(yr_sc[,3], col = "darkorange2")

legend("topleft",
       legend = c("Active PIs","Turn-over"),
       col = c("sienna","darkorange2"),
       lty = 1,
       lwd = 1.619)

mtext(side = 3,
      "Yearly PI head-count and turnover\n(scaled)",
      line = 1.33,
      cex=1.3,
      font = 2)

ticks <- seq(from = 0, to = nrow(turnover_yr), length.out = 9)
axis(side = 1,
     at = ticks,
     las =2,
     labels = turnover_yr[ticks+1 ,"label"])


```

Discussion points:    

  - Turnover is calculated as the number of exits divided by the average head count of active researchers per period.
  - This calculation and graphic needs the same due diligence as noted previously (axis labels shifted and double-check of interval aggregations.)    
  - The general trend of increasing turnover, spiking last year, is somewhat alarming.  It may be worthwhile to compare PI turnover to turnover by all faculty.   

# TURNOVER BY COLLEGE

```{r}

colleges <- unique(prepData$college)
collegePIs <- lapply(colleges, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$college == x]))
names(collegePIs) <- colleges

collegeTurnover <- lapply(collegePIs, function(x){
  
  calculateTurnover(data=retData[retData$PI_EMPLID %in% x,] , interval = "year")
  
})

```


```{r}

# Kruskal-wallis

cT <- unlist( lapply(collegeTurnover, function(df) df[["to"]]))

kruskal.test(cT ~ names(cT))

cT.frame <- do.call(rbind, collegeTurnover)
cT.frame$college <- sub("\\..*", "", row.names(cT.frame))

college.kW <- kruskal.test(to ~ college, data = cT.frame)

```


```{r}

plot(1, 
     type = "n", 
     ylim = c(0.,0.3),  #c(-4,4), 
     xlim = c(2013,2026),
     xaxt = "n",
     xlab = "",
     ylab = "turnover")
lapply(collegeTurnover, function(x){
  lines((x[,"to"]), x = as.numeric(x[,"label"]), col = "gray40")
  
})

ticks <- seq(from = 2013, to = 2026, by = 2)
axis(side = 1,
     at = ticks,
     las =2,
     labels = ticks)

legend("topleft", legend = paste("p-value of", round(college.kW$p.value,2)), text.col = "red", bty = "n")

mtext(side = 3,
      text = "Turnover does not vary greatly by college",
      cex = 1.3,
      line= 2,
      font = 2)

mtext(side = 3,
      text = "(according to the Kruskal-Wallis test)",
      cex = 1,
      line = 0.5,
      font = 3)


```


Discussion points:    

  - Why do these lines end at different points?
  - This is a good graphic for plotly (enables hover-over)
  - Kruskal-Wallis test is a pretty rough check   
# TURNOVER BY COMPLEX CLUSTER


```{r}

complex_clusters <- levels(prepData$complex_cluster)

complexPIs <- lapply(complex_clusters, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$complex_cluster == x]))
names(complexPIs) <- complex_clusters

complexTurnover <- lapply(complexPIs, function(x){
  
  calculateTurnover(data=retData[retData$PI_EMPLID %in% x,] , interval = "year")
  
})

```

```{r}

# Kruskal-wallis

compT.frame <- do.call(rbind, complexTurnover)
compT.frame$complex_cluster <- sub("\\..*", "", row.names(compT.frame))

complex.kW <- kruskal.test(to ~ complex_cluster, data = compT.frame)

```


```{r}

plot(1, 
     type = "n", 
     ylim = c(0.,0.1),  #c(-4,4), 
     xlim = c(2013,2026),
     xaxt = "n",
     xlab = "",
     ylab = "turnover")
lapply(complexTurnover, function(x){
  lines((x[,"to"]), x = as.numeric(x[,"label"]), col = "gray40")
  
})

ticks <- seq(from = 2013, to = 2026, by = 2)
axis(side = 1,
     at = ticks,
     las =2,
     labels = ticks)

legend("topleft", legend = paste("p-value of", round(complex.kW$p.value,2)), text.col = "red", bty = "n")

mtext(side = 3,
      text = "Turnover does not vary greatly by cluster",
      cex = 1.3,
      line= 2,
      font = 2)

mtext(side = 3,
      text = "(according to the Kruskal-Wallis test)",
      cex = 1,
      line = 0.5,
      font = 3)


```

Discussion points:    

  - Why do these lines end at different points?
  - This is a good graphic for plotly (enables hover-over)
  - Kruskal-Wallis test is a pretty rough check
    * It isn't taking the time series into account
  - I'd like to add the cluster colors



# DATA DESCRIPTION

```{r include=TRUE}

skim(retData)

```

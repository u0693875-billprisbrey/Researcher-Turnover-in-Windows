---
title: "Retention Exploratory Data Analysis"
author: "Bill Prisbrey"
date: "2025-04-25"
output: html_document
---



```{r include=FALSE}

# Notes for author

# I am over-using the word "active."  I think I want "active" to mean the period they are "actively" proposing, and the word "current" to mean they are currently employed.  But what about then-current?  I guess I'll use the word "active" for proposing, and "employed" for then-employed.

# More thoughts:  
#  - Kruskal wallis is a nice general purpose first-look test, but I should probably find something more appropriate.
#  - Digging into how the intervals were aggregated should be informative (am I sure I'm doing it right?)


# Thoughts:

# - Re-name this as "exploratory data analysis" and summarize the new data view.  "Skimr" and a couple of histograms.
# - I'll probably uncover some data inconsistencies.
# - Use my new "activePI" function to calculate the number of active PI's every week.
# - Create a dataframe that is week-by-week active PI's
# - Use prepData to align proposing periods with hire or re-hire period EVENTUALLY
# - Lack of an initial termination date could be problematic

```


**PURPOSE:**  The purpose of this document is a "quick-and-dirty" or "back-of-the-envelope" exploration.  It briefly describes the retention data and superficially calculate and compare principal investigator turnover.  It will be used to determine if this project is worth pursuing and guide further data collection and transformation steps.   

**OBJECTIVES:**   

  1.  Describe the retention data.
  2.  Calculate and compare turnover    
      a.  By colleges    **DONE**  
      b.  By departments **NOT DONE**   
      c.  By PI clusters **DONE**    
      d.  By percentiles **TO BE DONE**    
  2.  Determine if there are differences and if they merit continuation of the project.         
  

**NOTES FROM REVIEW MEETING:**

This report was reviewed on 4.30.2025 with the following action item and summary.

Action Items:
- Dave to investigate negative and zero values for rehire-to-termination intervals (after Bill sends a list.)
- Dave to investigate:
	- Obtaining information that could describe voluntary and involuntary separation (who was fired vs who quit)
	- Obtaining birthdates from HR (so we can see if the declining number of PI's correlates with old age and retirement.)
- Bill to investigate: 
	- Proposal submission dates against the hire/rehire/termination intervals
	- Number of PI's submitting each year
	- Tighten up interval definitions and aggregations
	- Fix x-axis graph labeling
	- "Tendrils" on the per-week graph of active PI's
	- Compare the mean proposal award and see if it is climbing (to verify the declining number of PI's since COVID.)
	- Compare counts of hire/rehire/termination dates on the same graphic
	- Compare PI's submitting proposals against this view for completion's sake

Summary: 
- Bill asks how the view with the HR data is defined; what defines a PI for inclusion in this view?
- Rehire date is after the termination date in one case, and on the same day for a few others.  Dave will investigate. 	
- The lack of an initial termination date to pair with the initial hire date causes some confusion and guess-work as to when people are actually actively researching.  For example, if someone worked for a semester as a janitor as an undergrad, and then came back 15 years later as a researcher, the data will count her in the denominator of the turnover calculation for those 15 years.  This means the turnover calculation is incorrect.
- Bill wonders:  Can we identify voluntary vs involuntary separation?  --> Dave thinks there might be a "reason for update" field with a code attached to it in PS_JOB.
- The number of active PI's has declined since COVID.  Dave thinks this may be age and retirement.  Dave will try and get the birthday so we can include.
- The turnover has increased every year, dramatically increasing in 2024.
- This is a quick'n'dirty report with some problems:
	- The definition of "active researchers" has problematic assumptions as described above. 
	- The headcount of active researchers (between hire and termination date) by week has "tendrils" that need to be explained.
	- X-axis labels are shifted and interval aggregations need to be double-checked.
	- Kruskal-Wallis is not a very sensitive test nor the most appropriate for a time series
- A visual inspection of the "per cluster" trends shows two clusters moving together, one cluster consistently below the others, and two clusters with volatile and large turn-over.

**CONCLUSIONS AND NEXT STEPS:**

Several aspects of this report were intriguing:   

  - The increasing turnover, especially the spike in 2024       
  - The decline in PI headcount since COVID   
  - The visual inspection of turnover by cluster showing two clusters moving together and one cluster with a consistently lower turnover 
  
As well, many aspects of this report deserve a better treatment, including attempting to eliminate the guess-work introduced by the hire/rehire dates.

Due to these reasons, it was decided to continue investigating turnover by principal investigators.    

  
```{r include = FALSE}

knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, error=FALSE, fig.height=7, fig.width=10)

# adjust graphic parameters

oldPar <- par(cex.main = 3,
    cex.lab = 3,
    cex.axis = 2,
    mar = c(5.1,4.1,4.1,2.1), # default is c(5.1,4.1,4.1,2.1)
    mfrow = c(1,1)
    )

library(lubridate)

```

```{r}

###########
## QUERY ##
###########

# Obtain retention data

keyring::keyring_unlock(keyring = "BIPR", password = "Excelsior!")

library(DBI)
con.ds <- DBI::dbConnect(odbc::odbc(), Driver = "oracle", Host = "ocm-campus01.it.utah.edu", 
                         SVC = keyring::key_list(keyring = "BIPR")[1, 1], UID = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                    2], PWD = keyring::key_get(keyring = "BIPR", service = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                                                                                                               1]), Port = 2080)
retentionQuery <- "
SELECT *
FROM VPR.D_PI_EMP_DT_VW EMP_DATES
"

retData <- dbGetQuery(con.ds,
                      retentionQuery)


DBI::dbDisconnect(con.ds)




```


```{r}

##########
## LOAD ##
##########

# PREP SCRIPT

source(here::here("Prep scripts","Adjusting prepData and loading things.R"))


# PER PI

piClusters <- lapply(list.files(here::here("Robjects", "Clustering PIs"), full.names = TRUE), readRDS)

###########
## MERGE ## 
###########

piEmplid <- Reduce(function(x, y) {
  merged <- merge(x, y, by = "emplid", all = FALSE)
  merged <- merged[, !duplicated(sub("\\.x$|\\.y$", "", names(merged)))]  # Remove duplicate columns
  
  # Rename columns to remove ".x"
  names(merged) <- sub("\\.x$", "", names(merged))
  
  merged
}, piClusters)
# piEmplid <- Reduce(function(x, y) merge(x, y, by = "emplid", all = FALSE), piClusters)
# piEmplid <- do.call(merge, piClusters)



prepData <- merge(prepData, piEmplid[,c("emplid","complex_cluster","rate_cluster")], by.x =  "PROPOSAL_PI_EMPLID", by.y = "emplid", all.x = TRUE)

##########
## PREP ##
##########

piEmplid$combined_cluster <-  factor(paste(piEmplid$complex_cluster, piEmplid$rate_cluster, sep = ", "))

prepData$combined_cluster <- factor(paste(prepData$complex_cluster, prepData$rate_cluster, sep = ", "))

###############
## LIBRARIES ##
###############

library(viridis)
library(pheatmap)

#########
## MAP ##
#########

piMap <- data.frame(college = row.names(piEmplid), abbrv = row.names(piEmplid), color = NA, pch = 19, cex = 0.7 )

# I need the college map of colors

fullEmplid <- calculateWinRates(data = cleanData, categoryColumn = "PROPOSAL_PI_EMPLID") |>
  (\(x){x[[1]]})()

fullEmplid$count.total <- apply(fullEmplid[,c("win.count","loss.count")],1,sum)

filterTwoCount <- fullEmplid$count.total >= 2
# filterThreeCount <- piEmplid$count.total > 3


```


```{r}
             
# Manage colors

#############
## COMPLEX ##
#############

complexClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
                            "firebrick", "darkslategray", "chartreuse",  
                            "slateblue", "darkkhaki", "coral")

clusterComplexMapping <- piMap
clusterComplexMapping[,"pch"] <- rep(19, nrow(clusterComplexMapping))

clusterComplexMapping[,"color"] <- complexClusterColors [piEmplid$complex_cluster]

# clusterComplexMapping[,"color"] <- complexClusterColors[complexHCPC$data.clust$clust[match(clusterComplexMapping[,"college"], row.names(complexHCPC$data.clust))] ]

##############
## COMBINED ##
##############

combinedClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
  "firebrick", "darkslategray", "chartreuse",  
  "slateblue", "darkkhaki", "coral",  
  "mediumorchid", "dodgerblue", "tomato",  
  "orchid", "darkseagreen", "sienna",  
  "royalblue", "indianred", "seagreen",  
  "peru", "cadetblue", "plum",  
  "midnightblue", "lawngreen", "darkorange",  
  "lightsteelblue")

clusterCombinedMapping <- piMap
clusterCombinedMapping[,"pch"] <- rep(19, nrow(clusterCombinedMapping))

clusterCombinedMapping[,"color"] <- combinedClusterColors [piEmplid$combined_cluster]



################
## PERCENTILE ##
################

percentileColors <- viridis(10,direction = -1)[c(1:7,10)]
percentileMapping <- piMap

percentileMapping[,"pch"] <- rep(19, nrow(percentileMapping))

percentileMapping[,"color"] <- percentileColors[as.numeric(cut(piEmplid$win.sum_percentile, breaks = seq(0.2,1,by=0.1)))]

```

```{r}

##############################
## ACTIVE PROPOSING PERIODS ##
##############################

minDate <- aggregate(PROPOSAL_UPLOAD_DATE ~ PROPOSAL_PI_EMPLID, data = prepData, FUN =  function(x) {as.Date(min(x))})

maxDate <- aggregate(PROPOSAL_UPLOAD_DATE ~ PROPOSAL_PI_EMPLID, data = prepData, FUN = function(x) {as.Date(max(x))})

activeProposing <- merge(minDate, maxDate, by = "PROPOSAL_PI_EMPLID")
names(activeProposing) <- c("PROPOSAL_PI_EMPLID", "PROPOSAL_UPLOAD_DATE.min", "PROPOSAL_UPLOAD_DATE.max")

activeProposing <- merge(activeProposing, retData[,c("PI_EMPLID", "HIRE_DT", "REHIRE_DT", "TERMINATION_DT")],
               by.x = "PROPOSAL_PI_EMPLID",
               by.y = "PI_EMPLID",
               all.x = TRUE)

```



```{r eval = FALSE}


# Not sure these need their own columns
activeProposing$active <- time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.min, activeProposing$PROPOSAL_UPLOAD_DATE.max), unit = "year")

condition <- is.na(activeProposing$TERMINATION_DT)
activeProposing$inactive_to_date[condition] <- time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max[condition], ymd("2025-05-01")), unit = "year")

activeProposing$inactive_to_term <- time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max, activeProposing$TERMINATION_DT), unit = "year")

# what intervals are interesting?
# hire-to-propose
# re-hire-to-propose
# last propose to term
# active-yet-inactive (yrs since last propose for current headcount)
# productive period (first to last publication)

# I need to differentiate "active"-ly proposing and "current"-ly headcount
# maybe I use "productive"

# I need to use the same logic and count the number of "productive PI's" per week
# And then maybe adjust for those who are current and will probably put out a new proposal

# I'd like to see when the "active" period is during a prof's career.  Are they done at age 50?

# And I can figure out the correct period to use by comparing the min proposing date and the max hire/rehire date that is less than that.

# Before I do that, though, I should compare the various intervals.



```


```{r}

##############################
## PICK HIRE OR REHIRE DATE ##
##############################

# I want:
#  Were they proposing between their hire and re-hire date?  Only before their re-hire date?
#  Were they proposing only after their re-hire date?
#  Were they proposing before AND after their re-hire date?

before_rehire <- activeProposing$PROPOSAL_UPLOAD_DATE.max <= activeProposing$REHIRE_DT

after_rehire <- activeProposing$PROPOSAL_UPLOAD_DATE.min >= activeProposing$REHIRE_DT

before_and_after <- activeProposing$PROPOSAL_UPLOAD_DATE.min <= activeProposing$REHIRE_DT &  activeProposing$PROPOSAL_UPLOAD_DATE.max >= activeProposing$REHIRE_DT
 
# I kinda wanna see a "hire timeline"
# similar to my timeline and timedots, but with hire/rehire/term marked
# and scale it to actual years


#> table(before_rehire)
#before_rehire
#FALSE  TRUE 
#  634   162 
#> table(after_rehire)
#after_rehire
#FALSE  TRUE 
#  191   605 
#> table(before_and_after)
#before_and_after
#FALSE  TRUE 
#  767    29 

# Check
#> table(before_rehire & after_rehire)
#
#FALSE 
#  796 
#> table(before_rehire & before_and_after)
 
#FALSE 
#  796 
#> table(after_rehire & before_and_after)

#FALSE 
#  796 

activeProposing$effective_hire <- activeProposing$HIRE_DT

rehire_condition <- after_rehire & !is.na(after_rehire)
activeProposing$effective_hire[rehire_condition] <- activeProposing$REHIRE_DT[rehire_condition] 

  
```


```{r}

# modified timeline
# I want to modify the timeline to plot against the years
# and include the hire/rehire/termination dates

# a good picture is worth a thousand words.



```

# DURATIONS

```{r}

###############
## DURATIONS ##
###############


histPar <- par(mfrow = c(3,1),
               mar = c(2,3,3,0),
               bg = "ivory",
               fg = "gray10")

minTwoCondition <- activeProposing$PROPOSAL_PI_EMPLID %in% row.names(fullEmplid)[filterTwoCount]
time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.min[minTwoCondition], activeProposing$PROPOSAL_UPLOAD_DATE.max[minTwoCondition]), unit = "year") |>
  hist(main = "Active proposing duration\n(from first to last proposal date in years)\n(minimum of two proposals)",
               col = "skyblue",
       ylab = "count of PIs")

time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max, activeProposing$TERMINATION_DT), unit = "year") |>
  hist(main = "Inactive period from last proposal to termination (years)",
               col = "deepskyblue",
       ylab = "count of PIs")

condition <- is.na(activeProposing$TERMINATION_DT)
 time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max[condition], ymd("2025-05-01")), unit = "year") |>
   hist(main = "Inactive period from last proposal to 30 April 2025 \n(employed as of data cut-off of 30 April 2025)",
               col = "dodgerblue",
       ylab = "count of PIs")

# Maybe active needs to be filtered to PI's with at least two proposals? DONE
 
 
# For people active in the hire date -- how long from hire until submission?
# For people active in the rehire date -- how long from re-hire until submission?
# For all of them -- how long from last submission until termination?

# Hire until first submission

# I can use filters here or I can create an "effective hire date" 
 
time_length(interval(activeProposing$effective_hire, activeProposing$PROPOSAL_UPLOAD_DATE.min), unit = "year") |> # max() # 50 yrs!
  hist(main = "Period from effective hire to first proposal")

# something is still wrong

time_length(interval(activeProposing$effective_hire, activeProposing$PROPOSAL_UPLOAD_DATE.min), unit = "year") |>
  (\(x){which(x == max(x))})()

# the problem is that I don't have good proposal data until 2013.
# so I should truncate this to people hired after 2013

hire2013 <- year(activeProposing$effective_hire) >= 2013
time_length(interval(activeProposing$effective_hire[hire2013], activeProposing$PROPOSAL_UPLOAD_DATE.min[hire2013]), unit = "year") |> # max() # 50 yrs!
  hist(main = "Period from effective hire to first proposal\(for hires after 2013)")

# there we go, that's a much better graphic


```


```{r}

#########################
## CALCULATE INTERVALS ##
#########################

# library(lubridate)

# This is the initial time between "hire date" and "re-hire date"
retData$initial <- time_length(interval(retData$HIRE_DT, retData$REHIRE_DT), unit = "year")

# This is the time between "re-hire date" and "termination date"
retData$rehire <- time_length(interval(retData$REHIRE_DT, retData$TERMINATION_DT), unit = "year")

# This is the time from initial hire to termination date
retData$hire <- time_length(interval(retData$HIRE_DT, retData$TERMINATION_DT), unit = "year")


```

```{r}

#######################
## DISPLAY INTERVALS ##
#######################

histPar <- par(mfrow = c(3,1), mar = c(2, 4.1, 1.1, 0.1)) # c(5.1,4.1,4.1,2.1)

hist(retData$initial,
     main = "Duration in years after hire until rehire",
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "lightgreen")
legend("topright", legend = paste( sum(is.na(retData$initial)), "NA values"), bty = "n", text.col = "red")

hist(retData$rehire,
     main = "Duration in years after rehire until termination",
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "seagreen")
legend("topright", legend = paste( sum(is.na(retData$rehire)), "NA values"), bty = "n", text.col = "red")


hist(retData$hire,
     main = "Duration in years after hire until termination",
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "darkgreen")
legend("topright", legend = paste( sum(is.na(retData$hire)), "NA values"), bty = "n", text.col = "red")

par(histPar)

```

Duration thoughts:    

  - The lack of a termination date before the re-hire date introduces guess-work.   
  - Some researchers are apparently hired as students and re-hired later in their career.    
  - Some researchers are apparently hired in retirement after their career. 
  - These durations need to be aligned with proposal submission dates.    
  - This shows that we currently have 2,994 active principal investigators.   

# DATES

```{r eval=FALSE}

plotPar <- par(bg = "ivory", fg = "gray20")
table(week(retData$TERMINATION_DT)) |>
  plot(xlab = "week of year",
       ylab = "Count of terminations per week",
       main = "PIs are mostly terminated around June 30th")

par(plotPar)

```

```{r eval=FALSE}

# Raw numbers, quarterly, individual graphics

plotPar <- par(mfrow = c(3,1), bg = "ivory", fg = "gray20")

table(paste(year(retData$HIRE_DT), quarter(retData$HIRE_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of hires",
       main = "Hires over time",
       col = "chocolate4")


table(paste(year(retData$REHIRE_DT), quarter(retData$REHIRE_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of re-hires",
       main = "Re-hires over time",
       col = "chocolate4")



table(paste(year(retData$TERMINATION_DT), quarter(retData$TERMINATION_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of terminations",
       main = "Terminations over time",
       col = "chocolate4")



par(plotPar)

# maybe a cumulative graphic?
# maybe scaled lines on the same graphic? (Gotta do this one!)

```



```{r}

# Raw numbers, yearly, individual graphics

plotPar <- par(mfrow = c(3,1), 
               bg = "ivory", 
               fg = "gray20",
               mar = c(2, 4.1, 2, 0.3)
               )

#mar = c(2, 4.1, 1.1, 0.1)) # c(5.1,4.1,4.1,2.1)

table(year(retData$HIRE_DT)) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of hires",
       main = "Hires over time",
       type = "l",
       col = "chocolate4")


table(year(retData$REHIRE_DT)) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of re-hires",
       main = "Re-hires over time",
       type = "b",
       col = "chocolate4")



table(year(retData$TERMINATION_DT)) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of terminations",
       main = "Terminations over time",
       type = "b",
       col = "chocolate4")



par(plotPar)

# maybe a cumulative graphic?
# maybe scaled lines on the same graphic? (Gotta do this one!)

```




# ACTIVE PRINCIPAL INVESTIGATORS


```{r}

########################
## CALCULATE TURNOVER ##
########################

turnover_wk <- calculateTurnover(data = retData, interval = "week")

turnover_qt <- calculateTurnover(data = retData, interval = "quarter")

turnover_yr <- calculateTurnover(data = retData, interval = "year")


```

```{r}

plotPar <- par(bg = "ivory", fg = "gray20")

plot(turnover_wk$hire,
     cex = 0.3,
     main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_wk$label[ticks+1],
     las = 2)

```

Discussion points:    

  - Some aspects of this graph appear to be mis-aligned due to how counts per interval were aggregated:
    - Axis labels  
    - Points not along the main curve   
    - This needs to be investigated   
  - The general pattern of an increasing count of PI's that peaked around the year 2020 and declined since needs to be confirmed    
  - Because the total money requested won has increased, this would mean the average per PI has increased.  This could be one double-check. 
  
# DATES

```{r}


plotPar <- par(bg = "ivory", fg = "gray20")

plot(turnover_wk$exit,
     cex = 0.3,
     main = "Count of PI's terminated",
     type = "l",
     col="darkorange2",
     ylab = "Count of terminated PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_wk$label[ticks+1],
     las = 2)




```

```{r}

qt_sc <- turnover_qt[,-(1:2)] |>
  scale()

yr_sc <- turnover_yr[,-(1:2)] |>
  scale()


```


```{r}

plot(1,
     ylim = c(min(qt_sc),max(qt_sc)),
     xlim = c(0,nrow(qt_sc)),
     type = "n",
     xaxt = "n",
     xlab = "",
     ylab = ""
)

lines(qt_sc[,1], col = "sienna")
lines(qt_sc[,3], col = "darkorange2")

legend("topleft",
       legend = c("Active PIs","Turn-over"),
       col = c("sienna","darkorange2"),
       lty = 1,
       lwd = 1.619)

mtext(side = 3,
      "Quarterly PI head-count and turnover\n(scaled)",
      line = 1.33,
      cex=1.3,
      font = 2)

ticks <- seq(from = 0, to = nrow(turnover_qt), length.out = 9)
axis(side = 1,
     at = ticks,
     las =2,
     labels = turnover_qt[ticks+1 ,"label"])



```

```{r}

plot(1,
     ylim = c(min(yr_sc),max(yr_sc)),
     xlim = c(0,nrow(yr_sc)),
     type = "n",
     xaxt = "n",
     xlab = "",
     ylab = ""
)

lines(yr_sc[,1], col = "sienna", lwd = 2)
lines(yr_sc[,3], col = "darkorange2")

legend("topleft",
       legend = c("Active PIs","Turn-over"),
       col = c("sienna","darkorange2"),
       lty = 1,
       lwd = 1.619)

mtext(side = 3,
      "Yearly PI head-count and turnover\n(scaled)",
      line = 1.33,
      cex=1.3,
      font = 2)

ticks <- seq(from = 0, to = nrow(turnover_yr), length.out = 9)
axis(side = 1,
     at = ticks,
     las =2,
     labels = turnover_yr[ticks+1 ,"label"])


```

Discussion points:    

  - Turnover is calculated as the number of exits divided by the average head count of active researchers per period.
  - This calculation and graphic needs the same due diligence as noted previously (axis labels shifted and double-check of interval aggregations.)    
  - The general trend of increasing turnover, spiking last year, is somewhat alarming.  It may be worthwhile to compare PI turnover to turnover by all faculty.   

# TURNOVER BY COLLEGE

```{r}

colleges <- unique(prepData$college)
collegePIs <- lapply(colleges, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$college == x]))
names(collegePIs) <- colleges

collegeTurnover <- lapply(collegePIs, function(x){
  
  calculateTurnover(data=retData[retData$PI_EMPLID %in% x,] , interval = "year")
  
})

```


```{r}

# Kruskal-wallis

cT <- unlist( lapply(collegeTurnover, function(df) df[["to"]]))

kruskal.test(cT ~ names(cT))

cT.frame <- do.call(rbind, collegeTurnover)
cT.frame$college <- sub("\\..*", "", row.names(cT.frame))

college.kW <- kruskal.test(to ~ college, data = cT.frame)

```


```{r}

plot(1, 
     type = "n", 
     ylim = c(0.,0.3),  #c(-4,4), 
     xlim = c(2013,2026),
     xaxt = "n",
     xlab = "",
     ylab = "turnover")
lapply(collegeTurnover, function(x){
  lines((x[,"to"]), x = as.numeric(x[,"label"]), col = "gray40")
  
})

ticks <- seq(from = 2013, to = 2026, by = 2)
axis(side = 1,
     at = ticks,
     las =2,
     labels = ticks)

legend("topleft", legend = paste("p-value of", round(college.kW$p.value,2)), text.col = "red", bty = "n")

mtext(side = 3,
      text = "Turnover does not vary greatly by college",
      cex = 1.3,
      line= 2,
      font = 2)

mtext(side = 3,
      text = "(according to the Kruskal-Wallis test)",
      cex = 1,
      line = 0.5,
      font = 3)


```


Discussion points:    

  - Why do these lines end at different points?
  - This is a good graphic for plotly (enables hover-over)
  - Kruskal-Wallis test is a pretty rough check   
# TURNOVER BY COMPLEX CLUSTER


```{r}

complex_clusters <- levels(prepData$complex_cluster)

complexPIs <- lapply(complex_clusters, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$complex_cluster == x]))
names(complexPIs) <- complex_clusters

complexTurnover <- lapply(complexPIs, function(x){
  
  calculateTurnover(data=retData[retData$PI_EMPLID %in% x,] , interval = "year")
  
})

```

```{r}

# Kruskal-wallis

compT.frame <- do.call(rbind, complexTurnover)
compT.frame$complex_cluster <- sub("\\..*", "", row.names(compT.frame))

complex.kW <- kruskal.test(to ~ complex_cluster, data = compT.frame)

```


```{r}

plot(1, 
     type = "n", 
     ylim = c(0.,0.1),  #c(-4,4), 
     xlim = c(2013,2026),
     xaxt = "n",
     xlab = "",
     ylab = "turnover")
lapply(complexTurnover, function(x){
  lines((x[,"to"]), x = as.numeric(x[,"label"]), col = "gray40")
  
})

ticks <- seq(from = 2013, to = 2026, by = 2)
axis(side = 1,
     at = ticks,
     las =2,
     labels = ticks)

legend("topleft", legend = paste("p-value of", round(complex.kW$p.value,2)), text.col = "red", bty = "n")

mtext(side = 3,
      text = "Turnover does not vary greatly by cluster",
      cex = 1.3,
      line= 2,
      font = 2)

mtext(side = 3,
      text = "(according to the Kruskal-Wallis test)",
      cex = 1,
      line = 0.5,
      font = 3)


```

Discussion points:    

  - Why do these lines end at different points?
  - This is a good graphic for plotly (enables hover-over)
  - Kruskal-Wallis test is a pretty rough check
    * It isn't taking the time series into account
  - I'd like to add the cluster colors



# DATA DESCRIPTION

```{r include=TRUE}

skim(retData)

```

# QUERY

VPR.D_PI_EMP_DT_VW as
  SELECT pi."PI_DIM_KEY",    
         pi."PI_EMPLID",    
         pi."PI_FIRST_NAME",    
         pi."PI_MIDDLE_NAME",    
         pi."PI_LAST_NAME",    
         pi."PI_NAME",    
         pi."PI_EMAIL_ADDRESS",    
         pi."PI_PHONE",    
         pi."PI_INDICATOR",    
         pi."IS_PI",    
         pi."PI_LOAD_DATE_TIME",    
         pi."PI_UPDATE_DATE_TIME",    
         emp.hire_dt,    
         emp.rehire_dt,    
         emp.termination_dt
         FROM osp.d_pi_vw pi
         LEFT JOIN uuetl_hr.PS_UU_EMPLOYMENT_VW emp ON pi.pi_emplid = emp.emplid
         
         
         
---
title: "Retention Exploratory Data Analysis"
author: "Bill Prisbrey"
date: "2025-04-25"
output: html_document
---



```{r include=FALSE}

# It's hard to re-write the flow of an existing report.
# I think it's easier to copy to a new place and start over.
# But I'll keep working on adapting this current one (with lots of frequent commits.)

# I like my new direction  -- it's like two chapters.
# Chapter 1 is the retention data by itself -- basically cleaning up the "quick'n'dirty" version.
# Chapter 2 is the combination, which will require adapting the functions and will probably tell a pretty different story.

# This will be quicker to produce than a blend, but it also won't be the best story-telling or have the best narrative flow.

# Notes for author

# I am over-using the word "active."  I think I want "active" to mean the period they are "actively" proposing, and the word "current" to mean they are currently employed.  But what about then-current?  I guess I'll use the word "active" for proposing, and "employed" for then-employed.

# More thoughts:  
#  - Kruskal wallis is a nice general purpose first-look test, but I should probably find something more appropriate.
#  - Digging into how the intervals were aggregated should be informative (am I sure I'm doing it right?)


# Thoughts:

# - Re-name this as "exploratory data analysis" and summarize the new data view.  "Skimr" and a couple of histograms.
# - I'll probably uncover some data inconsistencies.
# - Use my new "activePI" function to calculate the number of active PI's every week.
# - Create a dataframe that is week-by-week active PI's
# - Use prepData to align proposing periods with hire or re-hire period EVENTUALLY
# - Lack of an initial termination date could be problematic

```


**PURPOSE:**  The purpose of this document is to describe the retention data and its combination with the proposal data.    

**OBJECTIVES:**   

  1.  Describe the retention data.
  2.  Calculate and compare turnover    
      a.  By colleges    **DONE**  
      b.  By departments **NOT DONE**   
      c.  By PI clusters **DONE**    
      d.  By percentiles **TO BE DONE**    
  3.  Describe the combination of the retention data and the proposal data.   
  4.  Re-calculate and compare turnover   
      a.  By colleges      
      b.  By departments    
      c.  By PI clusters     
      d.  By percentiles 
  5.  Describe differences and identify avenues for further exploration and next steps.           

**NOTES FROM REVIEW MEETING:**

This report was reviewed on 4.30.2025 with the following action item and summary.

Action Items:
- Dave to investigate negative and zero values for rehire-to-termination intervals (after Bill sends a list.)
- Dave to investigate:
	- Obtaining information that could describe voluntary and involuntary separation (who was fired vs who quit)
	- Obtaining birthdates from HR (so we can see if the declining number of PI's correlates with old age and retirement.)
- Bill to investigate: 
	- Proposal submission dates against the hire/rehire/termination intervals
	- Number of PI's submitting each year
	- Tighten up interval definitions and aggregations
	- Fix x-axis graph labeling
	- "Tendrils" on the per-week graph of active PI's
	- Compare the mean proposal award and see if it is climbing (to verify the declining number of PI's since COVID.)
	- Compare counts of hire/rehire/termination dates on the same graphic
	- Compare PI's submitting proposals against this view for completion's sake

Summary: 
- Bill asks how the view with the HR data is defined; what defines a PI for inclusion in this view?
- Rehire date is after the termination date in one case, and on the same day for a few others.  Dave will investigate. 	
- The lack of an initial termination date to pair with the initial hire date causes some confusion and guess-work as to when people are actually actively researching.  For example, if someone worked for a semester as a janitor as an undergrad, and then came back 15 years later as a researcher, the data will count her in the denominator of the turnover calculation for those 15 years.  This means the turnover calculation is incorrect.
- Bill wonders:  Can we identify voluntary vs involuntary separation?  --> Dave thinks there might be a "reason for update" field with a code attached to it in PS_JOB.
- The number of active PI's has declined since COVID.  Dave thinks this may be age and retirement.  Dave will try and get the birthday so we can include.
- The turnover has increased every year, dramatically increasing in 2024.
- This is a quick'n'dirty report with some problems:
	- The definition of "active researchers" has problematic assumptions as described above. 
	- The headcount of active researchers (between hire and termination date) by week has "tendrils" that need to be explained.
	- X-axis labels are shifted and interval aggregations need to be double-checked.
	- Kruskal-Wallis is not a very sensitive test nor the most appropriate for a time series
- A visual inspection of the "per cluster" trends shows two clusters moving together, one cluster consistently below the others, and two clusters with volatile and large turn-over.

**CONCLUSIONS AND NEXT STEPS:**

Several aspects of this report were intriguing:   

  - The increasing turnover, especially the spike in 2024       
  - The decline in PI headcount since COVID   
  - The visual inspection of turnover by cluster showing two clusters moving together and one cluster with a consistently lower turnover 
  
As well, many aspects of this report deserve a better treatment, including attempting to eliminate the guess-work introduced by the hire/rehire dates.

Due to these reasons, it was decided to continue investigating turnover by principal investigators.    

  
```{r include = FALSE}

knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, error=FALSE, fig.height=7, fig.width=10)

# adjust graphic parameters

oldPar <- par(cex.main = 3,
    cex.lab = 3,
    cex.axis = 2,
    mar = c(5.1,4.1,4.1,2.1), # default is c(5.1,4.1,4.1,2.1)
    mfrow = c(1,1)
    )

library(lubridate)

```

```{r}

###########
## QUERY ##
###########

# Obtain retention data

keyring::keyring_unlock(keyring = "BIPR", password = "Excelsior!")

library(DBI)
con.ds <- DBI::dbConnect(odbc::odbc(), Driver = "oracle", Host = "ocm-campus01.it.utah.edu", 
                         SVC = keyring::key_list(keyring = "BIPR")[1, 1], UID = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                    2], PWD = keyring::key_get(keyring = "BIPR", service = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                                                                                                               1]), Port = 2080)
retentionQuery <- "
SELECT *
FROM VPR.D_PI_EMP_DT_VW EMP_DATES
"

retData <- dbGetQuery(con.ds,
                      retentionQuery)


DBI::dbDisconnect(con.ds)




```


```{r}

##########
## LOAD ##
##########

# PREP SCRIPT

source(here::here("Prep scripts","Adjusting prepData and loading things.R"))


# PER PI

piClusters <- lapply(list.files(here::here("Robjects", "Clustering PIs"), full.names = TRUE), readRDS)

###########
## MERGE ## 
###########

piEmplid <- Reduce(function(x, y) {
  merged <- merge(x, y, by = "emplid", all = FALSE)
  merged <- merged[, !duplicated(sub("\\.x$|\\.y$", "", names(merged)))]  # Remove duplicate columns
  
  # Rename columns to remove ".x"
  names(merged) <- sub("\\.x$", "", names(merged))
  
  merged
}, piClusters)
# piEmplid <- Reduce(function(x, y) merge(x, y, by = "emplid", all = FALSE), piClusters)
# piEmplid <- do.call(merge, piClusters)



prepData <- merge(prepData, piEmplid[,c("emplid","complex_cluster","rate_cluster")], by.x =  "PROPOSAL_PI_EMPLID", by.y = "emplid", all.x = TRUE)

##########
## PREP ##
##########

piEmplid$combined_cluster <-  factor(paste(piEmplid$complex_cluster, piEmplid$rate_cluster, sep = ", "))

prepData$combined_cluster <- factor(paste(prepData$complex_cluster, prepData$rate_cluster, sep = ", "))

###############
## LIBRARIES ##
###############

library(viridis)
library(pheatmap)

#########
## MAP ##
#########

piMap <- data.frame(college = row.names(piEmplid), abbrv = row.names(piEmplid), color = NA, pch = 19, cex = 0.7 )

# I need the college map of colors

fullEmplid <- calculateWinRates(data = cleanData, categoryColumn = "PROPOSAL_PI_EMPLID") |>
  (\(x){x[[1]]})()

fullEmplid$count.total <- apply(fullEmplid[,c("win.count","loss.count")],1,sum)

filterTwoCount <- fullEmplid$count.total >= 2
# filterThreeCount <- piEmplid$count.total > 3


```


```{r}
             
# Manage colors

#############
## COMPLEX ##
#############

complexClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
                            "firebrick", "darkslategray", "chartreuse",  
                            "slateblue", "darkkhaki", "coral")

names(complexClusterColors) <- c(as.character(1:5),"unassigned") # I'll surely regret this

clusterComplexMapping <- piMap
clusterComplexMapping[,"pch"] <- rep(19, nrow(clusterComplexMapping))

clusterComplexMapping[,"color"] <- complexClusterColors [piEmplid$complex_cluster]

# clusterComplexMapping[,"color"] <- complexClusterColors[complexHCPC$data.clust$clust[match(clusterComplexMapping[,"college"], row.names(complexHCPC$data.clust))] ]

##############
## COMBINED ##
##############

combinedClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
  "firebrick", "darkslategray", "chartreuse",  
  "slateblue", "darkkhaki", "coral",  
  "mediumorchid", "dodgerblue", "tomato",  
  "orchid", "darkseagreen", "sienna",  
  "royalblue", "indianred", "seagreen",  
  "peru", "cadetblue", "plum",  
  "midnightblue", "lawngreen", "darkorange",  
  "lightsteelblue")

clusterCombinedMapping <- piMap
clusterCombinedMapping[,"pch"] <- rep(19, nrow(clusterCombinedMapping))

clusterCombinedMapping[,"color"] <- combinedClusterColors [piEmplid$combined_cluster]



################
## PERCENTILE ##
################

percentileColors <- viridis(10,direction = -1)[c(1:7,10)]
percentileMapping <- piMap

percentileMapping[,"pch"] <- rep(19, nrow(percentileMapping))

percentileMapping[,"color"] <- percentileColors[as.numeric(cut(piEmplid$win.sum_percentile, breaks = seq(0.2,1,by=0.1)))]

#############
## COLLEGE ##
#############

collegeAbbrv <- cbind(
  college = c(sweet16, bigInst, "other"),
  abbrv = c("Arch",
            "Educ",
            "FinArt",
            "Health",
            "Hum",
            "Nurs",
            "Pharm",
            "Science",
            "SocBeh",
            "SocWrk",
            "Bus",
            "Law",
            "Tran",
            "Dent",
            "Med",
            "Engr",
            "EGI",
            "Hunt",
            "SCI",
            "CVRTI",
            "ICSE",
            "CTSI",
            "other"
  ),
  color = c(
    "lightslategray",
    "orange",
    "cyan", 
    "hotpink", 
    "brown", 
    "darkgoldenrod", 
    "gold", 
    "green",
    "navy", 
    "magenta", 
    "olivedrab4", 
    "salmon", 
    "darkgreen",
    "yellowgreen", 
    "red",
    "blue",
    "chocolate", 
    "purple",
    "violet", 
    "khaki",
    "deepskyblue3",
    "chartreuse",
    "darkmagenta"
  ),
  pch = c(
    1,14,15,2,3,4,17,6,5,8,9,10,11,12,13,0,16,7,18, 23, 24, 25, 20  
    
    
  ),
  
  cex = rep(NA, length(c(sweet16, bigInst, "other")) )
)

collegeColors <- setNames(collegeAbbrv[,"color"], collegeAbbrv[,"abbrv"])

```

```{r}

##############################
## ACTIVE PROPOSING PERIODS ##
##############################

minDate <- aggregate(PROPOSAL_UPLOAD_DATE ~ PROPOSAL_PI_EMPLID, data = prepData, FUN =  function(x) {as.Date(min(x))})

maxDate <- aggregate(PROPOSAL_UPLOAD_DATE ~ PROPOSAL_PI_EMPLID, data = prepData, FUN = function(x) {as.Date(max(x))})

activeProposing <- merge(minDate, maxDate, by = "PROPOSAL_PI_EMPLID")
names(activeProposing) <- c("PROPOSAL_PI_EMPLID", "PROPOSAL_UPLOAD_DATE.min", "PROPOSAL_UPLOAD_DATE.max")

activeProposing <- merge(activeProposing, retData[,c("PI_EMPLID", "HIRE_DT", "REHIRE_DT", "TERMINATION_DT")],
               by.x = "PROPOSAL_PI_EMPLID",
               by.y = "PI_EMPLID",
               all.x = TRUE)

```



```{r eval = FALSE}


# Not sure these need their own columns
activeProposing$active <- time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.min, activeProposing$PROPOSAL_UPLOAD_DATE.max), unit = "year")

condition <- is.na(activeProposing$TERMINATION_DT)
activeProposing$inactive_to_date[condition] <- time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max[condition], ymd("2025-05-01")), unit = "year")

activeProposing$inactive_to_term <- time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max, activeProposing$TERMINATION_DT), unit = "year")

# what intervals are interesting?
# hire-to-propose
# re-hire-to-propose
# last propose to term
# active-yet-inactive (yrs since last propose for current headcount)
# productive period (first to last publication)

# I need to differentiate "active"-ly proposing and "current"-ly headcount
# maybe I use "productive"

# I need to use the same logic and count the number of "productive PI's" per week
# And then maybe adjust for those who are current and will probably put out a new proposal

# I'd like to see when the "active" period is during a prof's career.  Are they done at age 50?

# And I can figure out the correct period to use by comparing the min proposing date and the max hire/rehire date that is less than that.

# Before I do that, though, I should compare the various intervals.



```


```{r}

##############################
## PICK HIRE OR REHIRE DATE ##
##############################

# I want:
#  Were they proposing between their hire and re-hire date?  Only before their re-hire date?
#  Were they proposing only after their re-hire date?
#  Were they proposing before AND after their re-hire date?

before_rehire <- activeProposing$PROPOSAL_UPLOAD_DATE.max <= activeProposing$REHIRE_DT

after_rehire <- activeProposing$PROPOSAL_UPLOAD_DATE.min >= activeProposing$REHIRE_DT

before_and_after <- activeProposing$PROPOSAL_UPLOAD_DATE.min <= activeProposing$REHIRE_DT &  activeProposing$PROPOSAL_UPLOAD_DATE.max >= activeProposing$REHIRE_DT
 
# I kinda wanna see a "hire timeline"
# similar to my timeline and timedots, but with hire/rehire/term marked
# and scale it to actual years


#> table(before_rehire)
#before_rehire
#FALSE  TRUE 
#  634   162 
#> table(after_rehire)
#after_rehire
#FALSE  TRUE 
#  191   605 
#> table(before_and_after)
#before_and_after
#FALSE  TRUE 
#  767    29 

# Check
#> table(before_rehire & after_rehire)
#
#FALSE 
#  796 
#> table(before_rehire & before_and_after)
 
#FALSE 
#  796 
#> table(after_rehire & before_and_after)

#FALSE 
#  796 

activeProposing$effective_hire <- activeProposing$HIRE_DT

rehire_condition <- after_rehire & !is.na(after_rehire)
activeProposing$effective_hire[rehire_condition] <- activeProposing$REHIRE_DT[rehire_condition] 

  
```


```{r}

# modified timeline
# I want to modify the timeline to plot against the years
# and include the hire/rehire/termination dates

# a good picture is worth a thousand words.



```

#1) DESCRIBE THE RETENTION DATA   

Put a few words here describing the query.

Put a few words here describing "skimr" results -- number of rows, PI's, hires, re-hires, and terminations.

Then explain the handful of graphics that I want to show here.  Show the graphics under their own headings.

### Retention dates

```{r}

# Raw numbers, yearly, individual graphics

plotPar <- par(mfrow = c(3,1), 
               bg = "ivory", 
               fg = "gray20",
               mar = c(2, 4.1, 2, 0.3)
               )

#mar = c(2, 4.1, 1.1, 0.1)) # c(5.1,4.1,4.1,2.1)

table(year(retData$HIRE_DT)) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of hires",
       main = "Hires over time",
       type = "l",
       col = "chocolate4")


table(year(retData$REHIRE_DT)) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of re-hires",
       main = "Re-hires over time",
       type = "b",
       col = "chocolate4")



table(year(retData$TERMINATION_DT)) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of terminations",
       main = "Terminations over time",
       type = "b",
       col = "chocolate4")



par(plotPar)

# maybe a cumulative graphic?
# maybe scaled lines on the same graphic? (Gotta do this one!)

```



### Retention intervals

```{r}

#########################
## CALCULATE INTERVALS ##
#########################

# library(lubridate)

# This is the initial time between "hire date" and "re-hire date"
retData$initial <- time_length(interval(retData$HIRE_DT, retData$REHIRE_DT), unit = "year")

# This is the time between "re-hire date" and "termination date"
retData$rehire <- time_length(interval(retData$REHIRE_DT, retData$TERMINATION_DT), unit = "year")

# This is the time from initial hire to termination date
retData$hire <- time_length(interval(retData$HIRE_DT, retData$TERMINATION_DT), unit = "year")


```

```{r}

#######################
## DISPLAY INTERVALS ##
#######################

histPar <- par(mfrow = c(3,1), mar = c(2.5, 4.1, 2.6, 0.1)) # c(5.1,4.1,4.1,2.1)

hist(retData$initial,
     main = "Interval in years after hire until rehire",
     cex.main = 1.382,
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "lightseagreen")
legend("topright", legend = paste( format(sum(is.na(retData$initial)), big.mark = ","), "NA values"), bty = "n", text.col = "red", cex = 1.618)

hist(retData$rehire,
     main = "Interval in years after rehire until termination",
     cex.main = 1.382,
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "lightgreen")
legend("topright", legend = paste(format( sum(is.na(retData$rehire)), big.mark=",") , "NA values"), bty = "n", text.col = "red", cex = 1.618)


hist(retData$hire,
     main = "Interval in years after hire until termination",
     cex.main = 1.382,
     ylab = "Count",
     xlab = "", # "Duration in years",
     col = "aquamarine")
legend("topright", legend = paste(format( sum(is.na(retData$hire)), big.mark= ","), "NA values"), bty = "n", text.col = "red", cex = 1.618)

par(histPar)

```

Duration thoughts:    

  - The lack of a termination date before the re-hire date introduces guess-work.   
  - Some researchers are apparently hired as students and re-hired later in their career.    
  - Some researchers are apparently hired in retirement after their career. 
  - These durations need to be aligned with proposal submission dates.    
  - This shows that we currently have 2,994 active principal investigators.   

### Seasonality

```{r}

# I like this graphic.
# Convert it to three lines for my three date columns.
# Maybe move this after "dates" and before "intervals."

weeklyTerms <- table(week(retData$TERMINATION_DT))
weeklyHires <- table(week(retData$HIRE_DT))
weeklyRehires <- table(week(retData$REHIRE_DT))

yLim <- c(min(c(weeklyTerms, weeklyHires,weeklyRehires), na.rm = TRUE), max(c(weeklyTerms, weeklyHires,weeklyRehires), na.rm = TRUE) )

plotPar <- par(bg = "ivory", fg = "gray20")

plot(weeklyTerms,
     ylim = yLim,
     type = "n",
     ylab = "",
     las = 1,
     xlab = "week of year")

points(weeklyHires,
       type = "l",
       col = "purple")

points(weeklyRehires,
       type = "l",
       col = "orange")

points(weeklyTerms,
       type = "l",
       col = "firebrick")

mtext(side = 3,
      "Workforce flow has strong seasonality\nwith most activity happening in Week 26",
      font =2,
      cex = 1.384,
      line = 1)

legend("topleft",
       legend = c("hire","rehire","termination"),
       col = c("purple","orange", "firebrick"),
       pch = 15,
       pt.cex = 2)

par(plotPar)



table(week(retData$TERMINATION_DT)) |>
  plot(xlab = "week of year",
       ylab = "Count of terminations per week",
       main = "PIs are mostly terminated around June 30th")



```

```{r eval=FALSE}

# I decided to use the annual one instead (converted to a line chart)

# Raw numbers, quarterly, individual graphics

plotPar <- par(mfrow = c(3,1), bg = "ivory", fg = "gray20")

table(paste(year(retData$HIRE_DT), quarter(retData$HIRE_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of hires",
       main = "Hires over time",
       col = "chocolate4")


table(paste(year(retData$REHIRE_DT), quarter(retData$REHIRE_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of re-hires",
       main = "Re-hires over time",
       col = "chocolate4")



table(paste(year(retData$TERMINATION_DT), quarter(retData$TERMINATION_DT), sep = "-")) |>
  (\(x){ 
    x[names(x) != "NA-NA"]
    })() |>
  plot(ylab = "Count of terminations",
       main = "Terminations over time",
       col = "chocolate4")



par(plotPar)

# maybe a cumulative graphic?
# maybe scaled lines on the same graphic? (Gotta do this one!)

```



#2) CALCULATE AND COMPARE TURNOVER

### Active principal investigators

Except this is the date between "hire" and "rehire", so it's not accurate. 

"Active" is not a good term.

```{r}

########################
## CALCULATE TURNOVER ##
########################

calendar <- c("day","week", "month", "quarter", "year")

fullSpan <- lapply(calendar, function(x){
  
  calculateMetrics(calendar = x,
                   minDate = ymd("1960-01-01"),
                   maxDate = today(),
                   data = retData)
  
})
names(fullSpan) <- calendar

midSpan <- lapply(calendar, function(x){
  
  calculateMetrics(calendar = x,
                   minDate = ymd("2013-01-01"),
                   maxDate = today(),
                   data = retData)
  
})
names(midSpan) <- calendar

earlySpan <- lapply(calendar, function(x){
  
  calculateMetrics(calendar = x,
                   minDate = ymd("2000-01-01"),
                   maxDate = ymd("2020-12-31"),
                   data = retData)
  
})
names(earlySpan) <- calendar

lateSpan <- lapply(calendar, function(x){
  
  calculateMetrics(calendar = x,
                   minDate = ymd("2020-01-01"),
                   maxDate = today(),
                   data = retData)
  
})
names(lateSpan) <- calendar

```

```{r}

plotMetrics(
  data = fullSpan[["year"]],
  plotList = "all",
  title_mtext_params = list(text = "Approximate PI Headcount\nrehire dates ignored", line = -1.618),
  cumulative_plot_params = list(mar = c(0,6,3,1))
)


plotMetrics(
  data = midSpan[["year"]],
  plotList = "all",
    title_mtext_params = list(text = "Approximate PI Headcount\nrehire dates ignored", line = -1.618),
  cumulative_plot_params = list(mar = c(0,6,3,1))
)

```


I need some words like

[x] number of PI's have hire and rehire dates.  This creates uncertainty in the data as there is only one termination date.

Therefore, only the hire date is used.  And the re-hire date is completely ignored.

This means that individuals are counted after their hire date.  "Headcount" includes individuals who are after their hire date and before their termination date.

It means I am including someone who might have worked as a janitor during their undergraduate years, quit upon graduation, and have been elsewhere.

It also means that I am including someone who 

(room with hallway graphic (?))

Let's show a graphic with the re-hires removed completely.

I really need to emphasize my uncertainty with this data and graphic.  There's a strong guess here, or this reflects an assumption that is wrong.

Probably a discussion on how my hire and departure rates are calculated on an avg headcount basis.

And, what if this is COMPLETELY wrong?  Like, laughably and insanely wrong?

It might be a good time to walk through the SQL logic, too.

I should pull up a specific example of where I think they were a student, and where they were re-hired after their career.

```{r eval = FALSE}

# Removing the re-hires
# I don't think there's a point in showing this graphic.

calculateMetrics(calendar = "year",
                 minDate = ymd("2013-01-01"),
                 maxDate = today(),
                 data = retData[is.na(retData$REHIRE_DT),]) |>
  (\(x){
  plotMetrics(
      data = x,
  plotList = "all",
    title_mtext_params = list(text = "Approximate PI Headcount\nrehires removed", line = -1.618),
  cumulative_plot_params = list(mar = c(0,6,3,1))
  )})()


```

```{r eval=FALSE}

########################
## CALCULATE TURNOVER ##
########################

turnover_wk <- calculateTurnover(data = retData, interval = "week")

turnover_qt <- calculateTurnover(data = retData, interval = "quarter")

turnover_yr <- calculateTurnover(data = retData, interval = "year")


```

```{r eval=FALSE}

# delete me sooner rather than later

plotPar <- par(mfrow = c(3,1), 
               bg = "ivory", 
               fg = "gray20",
               mar = c(4, 4.1, 2, 0.3)
               )

plot(turnover_wk$hire,
     cex = 0.3,
     main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_wk$label[ticks+1],
     las = 2)

plot(turnover_qt$hire,
     cex = 0.3,
     main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_qt), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_qt$label[ticks+1],
     las = 2)

plot(turnover_yr$hire,
     cex = 0.3,
     main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_yr), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_yr$label[ticks+1],
     las = 2)



```


[FIXED discussion points]
  - Some aspects of this graph appear to be mis-aligned due to how counts per interval were aggregated:
    - Axis labels  
    - Points not along the main curve   
    - This needs to be investigated   
    
[RELEVANT discussion points]    
  - The general pattern of an increasing count of PI's that peaked around the year 2020 and declined since needs to be confirmed    
  - Because the total money requested won has increased, this would mean the average per PI has increased.  This could be one double-check. 


```{r eval=FALSE}

# I can delete this
# investigating the "tendrils"

plotPar <- par(mfrow = c(1,1), 
               bg = "ivory", 
               fg = "gray20",
               mar = c(4, 4.1, 4, 0.3)
               )

dateFilter <- turnover_wk$termDT > as.Date("2018-12-01") & turnover_wk$termDT <= as.Date("2020-06-01")

range(scale(turnover_wk$exit[dateFilter]))

plot(scale(turnover_wk$hire[dateFilter]),
     cex = 0.3,
     main = "Count of PI's between hire and termination date \ndoesn't align with exits",
     #main = "Count of PI's between hire and termination date",
     col="sienna",
     ylab = "Count of active PIs",
     xlab = "",
     xaxt = "n",
     type = "l",
     ylim = c(-2,9)
     )

# that's a little clearer what's going on.
# looks like these tendrils simply align with terminations and hires

# So now I'm trying to align them graphically

points(scale(turnover_wk$exit[dateFilter]),
     cex = 0.3,
     # main = "Count of PI's terminated",
     type = "l",
     col="red",
     ylab = "Count of terminated PIs",
     xlab = "",
     xaxt = "n")

legend("topright",
       legend = c("head count", "exit count"),
       lty = 1,
       lwd = 2,
       col = c("sienna","red"),
       cex = 1.3)

#ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
#axis(side = 1,
#     at = ticks,
#     labels = turnover_wk$label[ticks+1],
#     las = 2)

mtext(side = 1, line = 1.33, "This graph shows weekly calculations between 2018-12-01 and 2020-06-01")

mtext(side = 1, line = 2.33, "The misalignment suggests an error in the aggregating formula.")

par(plotPar)



```

  

```{r eval=FALSE}


plotPar <- par(bg = "ivory", fg = "gray20")

plot(turnover_wk$exit,
     cex = 0.3,
     main = "Count of PI's terminated",
     type = "l",
     col="darkorange2",
     ylab = "Count of terminated PIs",
     xlab = "",
     xaxt = "n")

ticks = seq(from = 0, to = nrow(turnover_wk), length.out = 12)
axis(side = 1,
     at = ticks,
     labels = turnover_wk$label[ticks+1],
     las = 2)




```

```{r eval=FALSE}

qt_sc <- turnover_qt[,-(1:2)] |>
  scale()

yr_sc <- turnover_yr[,-(1:2)] |>
  scale()


```


```{r eval=FALSE}

plot(1,
     ylim = c(min(qt_sc),max(qt_sc)),
     xlim = c(0,nrow(qt_sc)),
     type = "n",
     xaxt = "n",
     xlab = "",
     ylab = ""
)

lines(qt_sc[,1], col = "sienna")
lines(qt_sc[,3], col = "darkorange2")

legend("topleft",
       legend = c("Active PIs","Turn-over"),
       col = c("sienna","darkorange2"),
       lty = 1,
       lwd = 1.619)

mtext(side = 3,
      "Quarterly PI head-count and turnover\n(scaled)",
      line = 1.33,
      cex=1.3,
      font = 2)

ticks <- seq(from = 0, to = nrow(turnover_qt), length.out = 9)
axis(side = 1,
     at = ticks,
     las =2,
     labels = turnover_qt[ticks+1 ,"label"])



```

```{r eval=FALSE}

# because the turnover is in error (based on assumptions we know are faulty) then there's not so much point in emphasizing or zooming in on this graphic or scaling it with the headcount.

# but the increasing departure rate is an interesting talking point.

plot(1,
     ylim = c(min(yr_sc),max(yr_sc)),
     xlim = c(0,nrow(yr_sc)),
     type = "n",
     xaxt = "n",
     xlab = "",
     ylab = ""
)

lines(yr_sc[,1], col = "sienna", lwd = 2)
lines(yr_sc[,3], col = "darkorange2")

legend("topleft",
       legend = c("Active PIs","Turn-over"),
       col = c("sienna","darkorange2"),
       lty = 1,
       lwd = 1.619)

mtext(side = 3,
      "Yearly PI head-count and turnover\n(scaled)",
      line = 1.33,
      cex=1.3,
      font = 2)

ticks <- seq(from = 0, to = nrow(turnover_yr), length.out = 9)
axis(side = 1,
     at = ticks,
     las =2,
     labels = turnover_yr[ticks+1 ,"label"])


```

Discussion points:    

  - Turnover is calculated as the number of exits divided by the average head count of active researchers per period.
  - This calculation and graphic needs the same due diligence as noted previously (axis labels shifted and double-check of interval aggregations.)    
  - The general trend of increasing turnover, spiking last year, is somewhat alarming.  It may be worthwhile to compare PI turnover to turnover by all faculty.   

# TURNOVER BY COLLEGE

I'm struggling if there's a point to do this.

Maybe just to develop the mechanics?

```{r}

colleges <- unique(prepData$college)
collegePIs <- lapply(colleges, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$college == x]))
names(collegePIs) <- colleges

collegeMetrics <- lapply(collegePIs, function(x){
  
  calculateMetrics(data=retData[retData$PI_EMPLID %in% x,],
                   minDate = ymd("2013-01-01"),
                   maxDate = today(), 
                     calendar = "year")
  
})


```


```{r eval=FALSE}

colleges <- unique(prepData$college)
collegePIs <- lapply(colleges, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$college == x]))
names(collegePIs) <- colleges

collegeTurnover <- lapply(collegePIs, function(x){
  
  calculateTurnover(data=retData[retData$PI_EMPLID %in% x,] , interval = "year")
  
})

```


```{r eval=FALSE}

# Waiting on better data with fewer assumptions

# Kruskal-wallis

cT <- unlist( lapply(collegeTurnover, function(df) df[["to"]]))

kruskal.test(cT ~ names(cT))

cT.frame <- do.call(rbind, collegeTurnover)
cT.frame$college <- sub("\\..*", "", row.names(cT.frame))

college.kW <- kruskal.test(to ~ college, data = cT.frame)

```


```{r eval=FALSE}

# Do this with the adjusted data,
# or better data if you get it (that doesn't ignore "rehire" date)

plot(1, 
     type = "n", 
     ylim = c(0.,0.3),  #c(-4,4), 
     xlim = c(2013,2026),
     xaxt = "n",
     xlab = "",
     ylab = "turnover")
lapply(collegeTurnover, function(x){
  lines((x[,"to"]), x = as.numeric(x[,"label"]), col = "gray40")
  
})

ticks <- seq(from = 2013, to = 2026, by = 2)
axis(side = 1,
     at = ticks,
     las =2,
     labels = ticks)

legend("topleft", legend = paste("p-value of", round(college.kW$p.value,2)), text.col = "red", bty = "n")

mtext(side = 3,
      text = "Turnover does not vary greatly by college",
      cex = 1.3,
      line= 2,
      font = 2)

mtext(side = 3,
      text = "(according to the Kruskal-Wallis test)",
      cex = 1,
      line = 0.5,
      font = 3)


```


Discussion points:    

  - Why do these lines end at different points?
  - This is a good graphic for plotly (enables hover-over)
  - Kruskal-Wallis test is a pretty rough check   
# TURNOVER BY COMPLEX CLUSTER


```{r}

complex_clusters <- levels(prepData$complex_cluster)

complexPIs <- lapply(complex_clusters, function(x) unique(prepData$PROPOSAL_PI_EMPLID[prepData$complex_cluster == x & !is.na(prepData$complex_cluster)]))
names(complexPIs) <- complex_clusters

# add the unassigned PI's, or NA values for prepData$complex_cluster

complexPIs[["unassigned"]] <- unique(prepData$PROPOSAL_PI_EMPLID[is.na(prepData$complex_cluster)])

complexMetrics <- lapply(complexPIs, function(x){
  
  calculateMetrics(data=retData[retData$PI_EMPLID %in% x,],
                    minDate = ymd("2013-01-01"),
                    maxDate = today(), 
                    calendar = "year")
  
})

```

```{r eval=FALSE}

# repeat with better data that doesn't ignore "rehire" date

# Kruskal-wallis

compT.frame <- do.call(rbind, complexTurnover)
compT.frame$complex_cluster <- sub("\\..*", "", row.names(compT.frame))

complex.kW <- kruskal.test(to ~ complex_cluster, data = compT.frame)

```


```{r eval=FALSE}

# re-do this with plotly and the correct cluster colors

plot(1, 
     type = "n", 
     ylim = c(0.,0.1),  #c(-4,4), 
     xlim = c(2013,2026),
     xaxt = "n",
     xlab = "",
     ylab = "turnover")
lapply(complexTurnover, function(x){
  lines((x[,"to"]), x = as.numeric(x[,"label"]), col = "gray40")
  
})

ticks <- seq(from = 2013, to = 2026, by = 2)
axis(side = 1,
     at = ticks,
     las =2,
     labels = ticks)

legend("topleft", legend = paste("p-value of", round(complex.kW$p.value,2)), text.col = "red", bty = "n")

mtext(side = 3,
      text = "Turnover does not vary greatly by cluster",
      cex = 1.3,
      line= 2,
      font = 2)

mtext(side = 3,
      text = "(according to the Kruskal-Wallis test)",
      cex = 1,
      line = 0.5,
      font = 3)


```

```{r eval=FALSE}

  p <- plot_ly(
    type = "scatter",
    mode = "lines",
    xaxis = list(title = "", range = c(2013,2026)),
    yaxis = list(title = "Departure rate", range = c(0,0.1))
  )
  
for(x in complexMetrics){
    
     p <- add_lines(p, 
                   x = as.numeric(x[, "adjDate"]),
                   y = 100*x[, "termRate"],
                   line = list(color = "gray40"),
                   showlegend = FALSE)
    
  }

# Needs a title
# Needs cluster colors
# Without reference to the cluster, it's pretty pointless
# This really doesn't need to be a "plotly" graphic.
# I can do this with the correct colors and a good legend that has the cluster nick-name.



```

```{r}

#########################
##        PLOT OF      ##
## METRICS PER CLUSTER ##
#########################

plotMetrics(data = complexMetrics,
            plotList = "all",
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="topleft"),
            delta_legend_params = list(plot=FALSE),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = "Head count metrics per cluster")
            )


#########################
##        PLOT OF      ##
## METRICS PER UNASSIGNED CLUSTER ##
#########################

plotMetrics(data = complexMetrics["unassigned"],
            plotList = "all",
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="topleft"),
            delta_legend_params = list(plot=FALSE),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = "Head count metrics per cluster")
            )

#########################
##        PLOT OF      ##
## METRICS PER 2 and 4 CLUSTER ##
#########################

plotMetrics(data = complexMetrics[c(2,4)],
            plotList = "all",
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="topleft"),
            delta_legend_params = list(plot=FALSE),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = "Head count metrics per clusters 2 and 4")
            )


#########################
##        PLOT OF      ##
## METRICS PER 1 and 3 CLUSTER ##
#########################

plotMetrics(data = complexMetrics[c(1,3)],
            plotList = "all",
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="topleft"),
            delta_legend_params = list(plot=FALSE),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = "Head count metrics per clusters 1 and 3")
            )


#########################
##        PLOT OF      ##
## METRICS PER 5 CLUSTER ##
#########################

plotMetrics(data = complexMetrics[5],
            plotList = "all",
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="topleft"),
            delta_legend_params = list(plot=FALSE),
            featureMap = complexClusterColors,
            title_mtext_params = list(text = "Head count metrics per cluster 5")
            )

```


```{r}

#########################
##        PLOT OF      ##
## METRICS PER COLLEGE ##
#########################

# Medicine

plotMetrics(data = collegeMetrics[c("Med")],
            plotList = "all",
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="left"),
            delta_legend_params = list(x="left"),
            featureMap = collegeColors,
            title_mtext_params = list(text = "Head count metrics (Medicine)")
            )

# Next three

plotMetrics(data = collegeMetrics[c("Hunt","Engr","Science")],
            plotList = "all",
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x="left"),
            delta_legend_params = list(x="bottomleft"),
            featureMap = collegeColors,
            title_mtext_params = list(text = "Head count metrics (three large organizations)")
            )

# Everyone else

plotMetrics(data = collegeMetrics[!names(collegeMetrics) %in% c("Med", "Hunt","Engr","Science")],
            plotList = "all",
            term_points_params = list(type = "l", lwd=2),
            hire_points_params = list(type = "l"),
            metric_legend_params = list(x = "top"),
            metric_legend2_params = list(plot = FALSE),
            delta_legend_params = list(plot = FALSE),
            featureMap = collegeColors,
            title_mtext_params = list(text = "Head count metrics (remaining organizations)")
            )

# DOES TERMINATION ALWAYS START AT ZERO? COUNT AND RATE?
# OR JUST FOR THIS DATA SELECTION?

```


Discussion points:    

  - Why do these lines end at different points?
  - This is a good graphic for plotly (enables hover-over)
  - Kruskal-Wallis test is a pretty rough check
    * It isn't taking the time series into account
  - I'd like to add the cluster colors

# TURNOVER BY PERCENTILES

```{r}

###########################
## CALCLUATE PERCENTILES ##
###########################

# I'm writing over my method for the complex_cluster.
# So you may be looking at a mix of new and old code here

piEmplid$win.sum_tile <- cut(piEmplid$win.sum_percentile, breaks = c(0,seq(0.2,1,by=0.1)), include.lowest = TRUE )

piPercentiles <- levels(piEmplid$win.sum_tile)

pisPerTile <- lapply(piPercentiles, function(x) unique(piEmplid$emplid[piEmplid$win.sum_tile == x]))
names(pisPerTile) <- piPercentiles

# add the unassigned PI's, or NA values for prepData$complex_cluster

pisPerTile[["unassigned"]] <- unique(prepData$PROPOSAL_PI_EMPLID[!(prepData$PROPOSAL_PI_EMPLID %in% unlist(pisPerTile))])

tileMetrics <- lapply(pisPerTile, function(x){
  
  calculateMetrics(data=retData[retData$PI_EMPLID %in% x,],
                    minDate = ymd("2013-01-01"),
                    maxDate = today(), 
                    calendar = "year")
  
})

```


```{r}

######################
## PLOT PERCENTILES ##
######################

tileColors <- c("burlywood1", percentileColors, "firebrick")
names(tileColors) <- names(tileMetrics)

plotMetrics(tileMetrics,
            plotList = "all",
            featureMap = tileColors
            )

plotMetrics(tileMetrics[!(names(tileMetrics) %in% "unassigned")],
            plotList = "all",
            featureMap = tileColors
            )


plotMetrics(
  data = fullSpan[["year"]],
  plotList = "all",
  title_mtext_params = list(text = "Approximate PI Headcount\nrehire dates ignored", line = -1.618),
  cumulative_plot_params = list(mar = c(0,6,3,1))
)


```

I am not understanding in the slightest how I have the largest headcount in the 90th percentile and then going down from there.

This needs some looking into.


# DATA DESCRIPTION

```{r include=TRUE}

skim(retData)

```

# QUERY

VPR.D_PI_EMP_DT_VW as
  SELECT pi."PI_DIM_KEY",    
         pi."PI_EMPLID",    
         pi."PI_FIRST_NAME",    
         pi."PI_MIDDLE_NAME",    
         pi."PI_LAST_NAME",    
         pi."PI_NAME",    
         pi."PI_EMAIL_ADDRESS",    
         pi."PI_PHONE",    
         pi."PI_INDICATOR",    
         pi."IS_PI",    
         pi."PI_LOAD_DATE_TIME",    
         pi."PI_UPDATE_DATE_TIME",    
         emp.hire_dt,    
         emp.rehire_dt,    
         emp.termination_dt
         FROM osp.d_pi_vw pi
         LEFT JOIN uuetl_hr.PS_UU_EMPLOYMENT_VW emp ON pi.pi_emplid = emp.emplid
 
#3) COMBINE RETENTION AND PROPOSAL DATA

  3.  Describe the combination of the retention data and the proposal data.
 

```{r}

###############
## DURATIONS ##
###############


histPar <- par(mfrow = c(3,1),
               mar = c(2,3,3,0),
               bg = "ivory",
               fg = "gray10")

minTwoCondition <- activeProposing$PROPOSAL_PI_EMPLID %in% row.names(fullEmplid)[filterTwoCount]
time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.min[minTwoCondition], activeProposing$PROPOSAL_UPLOAD_DATE.max[minTwoCondition]), unit = "year") |>
  hist(main = "Active proposing duration\n(from first to last proposal date in years)\n(minimum of two proposals)",
               col = "skyblue",
       ylab = "count of PIs")

time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max, activeProposing$TERMINATION_DT), unit = "year") |>
  hist(main = "Inactive period from last proposal to termination (years)",
               col = "deepskyblue",
       ylab = "count of PIs")

condition <- is.na(activeProposing$TERMINATION_DT)
 time_length(interval(activeProposing$PROPOSAL_UPLOAD_DATE.max[condition], ymd("2025-05-01")), unit = "year") |>
   hist(main = "Inactive period from last proposal to 30 April 2025 \n(employed as of data cut-off of 30 April 2025)",
               col = "dodgerblue",
       ylab = "count of PIs")

# Maybe active needs to be filtered to PI's with at least two proposals? DONE
 
 
# For people active in the hire date -- how long from hire until submission?
# For people active in the rehire date -- how long from re-hire until submission?
# For all of them -- how long from last submission until termination?

# Hire until first submission

# I can use filters here or I can create an "effective hire date" 
 
time_length(interval(activeProposing$effective_hire, activeProposing$PROPOSAL_UPLOAD_DATE.min), unit = "year") |> # max() # 50 yrs!
  hist(main = "Period from effective hire to first proposal")

# something is still wrong

time_length(interval(activeProposing$effective_hire, activeProposing$PROPOSAL_UPLOAD_DATE.min), unit = "year") |>
  (\(x){which(x == max(x))})()

# the problem is that I don't have good proposal data until 2013.
# so I should truncate this to people hired after 2013

# make this a precise date, the minimum in the prepData
hire2013 <- year(activeProposing$effective_hire) >= 2013
time_length(interval(activeProposing$effective_hire[hire2013], activeProposing$PROPOSAL_UPLOAD_DATE.min[hire2013]), unit = "year") |> # max() # 50 yrs!
  hist(main = "Period from effective hire to first proposal\n(for hires after 2013)")

# there we go, that's a much better graphic


```

Before I compare turnover by cluster, I need to add this descriptive bit:

all(prepData$PROPOSAL_PI_EMPLID %in% retData$PI_EMPLID) # TRUE (good)

table(retData$PI_EMPLID %in% prepData$PROPOSAL_PI_EMPLID)
FALSE  TRUE 
1538  2937 

And discuss how there are more PI's in the retData than are in my proposal data set, and that talking about clusters introduces a filter.

Presumably these 1,538 "FALSE" ones haven't proposed after 2013.    

It's probably a good time to disect that query a little more.
.... and here's what I'm seeing:

a "left join" onto osp.d_pi_vw.

So now I want to know how osp.d_pi_vw was created (how is it defined?) and how did it get 1,538 PI's that aren't in my proposal data?

Let's check that out --

My "prepData" had some cleaning on it.


...and how worth is my time to chase this down when I'm likely to get new information and better data after talking to HR?  I think I'll leave this one down.

It does raise the question.  From my complexMetrics, what's the first hire date?




         
         
---
title: "Dimensions Age Exploratory Data Analysis"
author: "Bill Prisbrey"
date: "2025-06-10"
output:
  html_document:
    keep_md: true
---


```{r settings, include = FALSE}

knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, error=FALSE,
                      fig.height=5, fig.width=7)

# fig.height=6.75, fig.width=12) for ppt
# fig.height=7, fig.width=10) typical report


# adjust graphic parameters

oldPar <- par(cex.main = 3,
    cex.lab = 3,
    cex.axis = 2,
    mar = c(5.1,4.1,4.1,2.1) # default is c(5.1,4.1,4.1,2.1)
    )

# par(oldPar) #restore old parameters # restore old parameters after the plot

```

```{r}

# developing a function to display categorical differences

plotCategory <- function(colname, wanted_label=NA) {
  
  table(fullPI[,c(colname, "class")]) |> 
  (\(x){ 
    
if (!all(is.na(wanted_label))) {
        original_names <- rownames(x)
        new_names <- ifelse(original_names %in% wanted_label, original_names, "")
        dimnames(x)[[1]] <- new_names
      }
    
    plot(x,
         main = gsub("_", " ", gsub("PROPOSAL_","", colname)),
         col = c("darkcyan","chocolate4"),
         cex = 1.2)
        
    })()
  
}


```



```{r}

##########
## LOAD ##
##########

# PREP SCRIPT

source(here::here("Prep scripts","Adjusting prepData and loading things.R"))

# LOAD MODEL 

xgbModel <- readRDS(here::here("Robjects", "Identifying missing age values from Dimensions Age Exploratory Data Analysis.rds"))

# PER PI

piClusters <- lapply(list.files(here::here("Robjects", "Clustering PIs"), full.names = TRUE), readRDS)

###########
## MERGE ## 
###########

piEmplid <- Reduce(function(x, y) {
  merged <- merge(x, y, by = "emplid", all = FALSE)
  merged <- merged[, !duplicated(sub("\\.x$|\\.y$", "", names(merged)))]  # Remove duplicate columns
  
  # Rename columns to remove ".x"
  names(merged) <- sub("\\.x$", "", names(merged))
  
  merged
}, piClusters)
# piEmplid <- Reduce(function(x, y) merge(x, y, by = "emplid", all = FALSE), piClusters)
# piEmplid <- do.call(merge, piClusters)



prepData <- merge(prepData, piEmplid[,c("emplid","complex_cluster","rate_cluster")], by.x =  "PROPOSAL_PI_EMPLID", by.y = "emplid", all.x = TRUE)

##########
## PREP ##
##########

piEmplid$combined_cluster <-  factor(paste(piEmplid$complex_cluster, piEmplid$rate_cluster, sep = ", "))

prepData$combined_cluster <- factor(paste(prepData$complex_cluster, prepData$rate_cluster, sep = ", "))

###############
## LIBRARIES ##
###############

library(viridis)
library(pheatmap)

#########
## MAP ##
#########

piMap <- data.frame(college = row.names(piEmplid), abbrv = row.names(piEmplid), color = NA, pch = 19, cex = 0.7 )

# I need the college map of colors

fullEmplid <- calculateWinRates(data = cleanData, categoryColumn = "PROPOSAL_PI_EMPLID") |>
  (\(x){x[[1]]})()

fullEmplid$count.total <- apply(fullEmplid[,c("win.count","loss.count")],1,sum)

filterTwoCount <- fullEmplid$count.total >= 2
# filterThreeCount <- piEmplid$count.total > 3


```


```{r}
             
# Manage colors

#############
## COMPLEX ##
#############

complexClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
                            "firebrick", "darkslategray", "chartreuse",  
                            "slateblue", "darkkhaki", "coral")

names(complexClusterColors) <- c(as.character(1:5),"unassigned") # I'll surely regret this

clusterComplexMapping <- piMap
clusterComplexMapping[,"pch"] <- rep(19, nrow(clusterComplexMapping))

clusterComplexMapping[,"color"] <- complexClusterColors [piEmplid$complex_cluster]

# clusterComplexMapping[,"color"] <- complexClusterColors[complexHCPC$data.clust$clust[match(clusterComplexMapping[,"college"], row.names(complexHCPC$data.clust))] ]

##############
## COMBINED ##
##############

combinedClusterColors <- c("forestgreen", "deepskyblue", "goldenrod",  
  "firebrick", "darkslategray", "chartreuse",  
  "slateblue", "darkkhaki", "coral",  
  "mediumorchid", "dodgerblue", "tomato",  
  "orchid", "darkseagreen", "sienna",  
  "royalblue", "indianred", "seagreen",  
  "peru", "cadetblue", "plum",  
  "midnightblue", "lawngreen", "darkorange",  
  "lightsteelblue")

clusterCombinedMapping <- piMap
clusterCombinedMapping[,"pch"] <- rep(19, nrow(clusterCombinedMapping))

clusterCombinedMapping[,"color"] <- combinedClusterColors [piEmplid$combined_cluster]



################
## PERCENTILE ##
################

percentileColors <- viridis(10,direction = -1)[c(1:7,10)]
percentileMapping <- piMap

percentileMapping[,"pch"] <- rep(19, nrow(percentileMapping))

percentileMapping[,"color"] <- percentileColors[as.numeric(cut(piEmplid$win.sum_percentile, breaks = seq(0.2,1,by=0.1)))]

#############
## COLLEGE ##
#############

collegeAbbrv <- cbind(
  college = c(sweet16, bigInst, "other"),
  abbrv = c("Arch",
            "Educ",
            "FinArt",
            "Health",
            "Hum",
            "Nurs",
            "Pharm",
            "Science",
            "SocBeh",
            "SocWrk",
            "Bus",
            "Law",
            "Tran",
            "Dent",
            "Med",
            "Engr",
            "EGI",
            "Hunt",
            "SCI",
            "CVRTI",
            "ICSE",
            "CTSI",
            "other"
  ),
  color = c(
    "lightslategray",
    "orange",
    "cyan", 
    "hotpink", 
    "brown", 
    "darkgoldenrod", 
    "gold", 
    "green",
    "navy", 
    "magenta", 
    "olivedrab4", 
    "salmon", 
    "darkgreen",
    "yellowgreen", 
    "red",
    "blue",
    "chocolate", 
    "purple",
    "violet", 
    "khaki",
    "deepskyblue3",
    "chartreuse",
    "darkmagenta"
  ),
  pch = c(
    1,14,15,2,3,4,17,6,5,8,9,10,11,12,13,0,16,7,18, 23, 24, 25, 20  
    
    
  ),
  
  cex = rep(NA, length(c(sweet16, bigInst, "other")) )
)

collegeColors <- setNames(collegeAbbrv[,"color"], collegeAbbrv[,"abbrv"])

```


```{r}

###########
## QUERY ##
###########

# Obtain age data

keyring::keyring_unlock(keyring = "BIPR", password = "Excelsior!")

library(DBI)
con.ds <- DBI::dbConnect(odbc::odbc(), Driver = "oracle", Host = "ocm-campus01.it.utah.edu", 
                         SVC = keyring::key_list(keyring = "BIPR")[1, 1], UID = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                    2], PWD = keyring::key_get(keyring = "BIPR", service = keyring::key_list(keyring = "BIPR")[1, 
                                                                                                                                                                                                               1]), Port = 2080)

ageQuery <- "
select
               dc.emplid,
               daa.first_pub_yr,
               daa.last_pub_yr,
               daa.total_publications,
               daa.first_pub_title,
               daa.first_pub_id,
               daa.first_grant_yr,
               daa.last_grant_yr,
               daa.total_grants,
               dc.dim_id,
               dc.confidence,
               dc.confidence_desc
from vpr_dimensions.dimensions_crosswalk dc
left join vpr_dimensions.ds_uu_academic_age daa on daa.uu_researcher_dim_id = dc.dim_id
"

ageData <- dbGetQuery(con.ds,
                      ageQuery)

DBI::dbDisconnect(con.ds)


```


```{r}

##########
## PREP ##
##########

ageData$CONFIDENCE <- factor(ageData$CONFIDENCE, levels = c(1:5, "W"))

###########
## MERGE ##
###########

prepAgeData <- merge(prepData, ageData, by.x = "PROPOSAL_PI_EMPLID" , by.y = "EMPLID", all.x = TRUE)

# due to ambiguous matches, there are multiple matches for some EMPLIDs

# length(unique(prepAgeData$PROPOSAL_PI_EMPLID[is.na(prepAgeData$CONFIDENCE)])) # 812 !

prepAgeData$class <- ifelse(is.na(prepAgeData$CONFIDENCE),"missing","present")

```



```{r}

## IDENTIFY DUPLICATE MATCHES

theDupes <- table(ageData[,c("EMPLID", "DIM_ID")]) |>
  as.data.frame.matrix() |>
    (\(x){apply(x, 1, sum)  })() |>
    (\(x){x[x>1]})()

nonDupes <- unique(ageData$EMPLID)[!unique(ageData$EMPLID) %in% names(theDupes)]  

```



**PURPOSE:**  The purpose of this report is to describe an aspect of the external Dimensions data set and its alignment with internal proposal data.


**OBJECTIVES:**   

  1.  Describe the Dimensions data.   
  2.  Describe alignment with internal data.    
  3.  Identify patterns in alignment.   
  
**SUMMARY:**   

The Dimensions data set is an external data set that tracks activity by researchers.  It is described [here.] (Find a link.)  

Internally, the Office of Sponsored Projects similarly tracks proposal activity by principal investigators.

The internal and external data sets can be aligned in order to have a more comprehensive evaluation of an individual's activity, both preceding and succeeding their time at the U.

For the purposes of evaluating PI turnover and retention, it is hoped that an "academic age" per PI can be derived from this data set based on their earliest publication [or grant?].  The "academic age" will be used as a proxy for actual age, as although employees' birthdates are known this information is considered PPI and subject to maximum restriction.

The internal and external data sets are aligned by matching researcher identification through clues such as name, department, and publication title.  However, external data sets are never perfect and often require manual curation.  A perfect alignment is not expected.

For the purposes of this analysis, date fields describing first and last publishing year or grant year, total number of publications and grants, and an alignment confidence score are extracted from the external data set.

The publication dates range from the year `r min(ageData$FIRST_PUB_YR, na.rm = TRUE)` to `r max(ageData$LAST_PUB_YR, na.rm = TRUE)`, and the grant dates range from the year `r min(ageData$FIRST_GRANT_YR, na.rm = TRUE)` to `r max(ageData$LAST_GRANT_YR, na.rm = TRUE)`.  `r sum(ageData$TOTAL_PUBLICATIONS, na.rm = TRUE) |> format(big.mark = ',')` publications and `r sum(ageData$TOTAL_GRANTS, na.rm = TRUE) |> format(big.mark = ',')` grants are tallied.

The combined data set attempts to align `r length(unique(ageData$EMPLID))` internal employee identification numbers with `r length(unique(ageData$DIM_ID))` external researcher identification numbers and provides a score of confidence in the alignment.  It aligns `r length(unique(ageData$EMPLID[ageData$EMPLID %in% nonDupes & ageData$CONFIDENCE == 1])) |> format(big.mark = ",")` (`r  (length(unique(ageData$EMPLID[ageData$EMPLID %in% nonDupes & ageData$CONFIDENCE == 1])) / length(unique(ageData$EMPLID))) |> (\(x){round(x*100,0)})() `%) internal EMPLIDs with a one-to-one match at the highest confidence score.  The remaining `r length(unique(ageData$EMPLID[!(ageData$EMPLID %in% nonDupes) | ageData$CONFIDENCE != 1]))` EMPLID's are aligned with multiple potential external ID's at reduced confidence levels.  

(Oddly, `r length(unique(ageData$EMPLID[ageData$EMPLID %in% names(theDupes) & ageData$CONFIDENCE == 1]))` EMPLID's are aligned with multiple external ID's with a confidence level of 1.)

However, internally OSP has tracked the research activity 



This evaluation found that 





Wow I'm struggling to write anything coherent.

The intent is to identify the first publication date per PI.

I actually don't need many words on this one.  The point is to get it done.  It's just a quick look at what we have.

Where's my graphic of how many are matched and un-matched?

It's like, instead of three tiles describing "duplicate" I need to add a fourth one on the right, the first one, which is

... is ....

... hold on ...

..."subset of interest" that is "found" and "not found" ?

I guess it's just another row of three.

Let's do that, first, and see what it looks like.





```{r}

skim(ageData)

```



### Grants and publication dates

```{r}

# First and last publication dates

plotPar <- par(mfrow = c(4,1), 
               bg = "ivory", 
               fg = "gray20",
               oma = c(1,0,0,0),
               mar = c(3, 4.1, 2, 0.3)
               )

#mar = c(2, 4.1, 1.1, 0.1)) # c(5.1,4.1,4.1,2.1)

table(ageData$FIRST_PUB_YR) |>
  plot(ylab = "Count of PI's",
       main = "Initial publication year",
       type = "l",
       las = 1,
       col = "forestgreen")


table(ageData$LAST_PUB_YR) |> log () |>
  plot(ylab = "Log count of PI's",
       main = "Final publication year",
       type = "b",
       cex = 0.619,
       las = 1,
       col = "darkolivegreen3")



table(ageData$FIRST_GRANT_YR) |>
  plot(ylab = "Count of PI's",
       main = "Initial grant year",
       type = "l",
       las = 1,
       col = "purple4")


table(ageData$LAST_GRANT_YR) |> log () |>
  plot(ylab = "Log count of PI's",
       main = "Final grant year",
       type = "b",
       cex = 0.619,
       las = 1,
       col = "orchid")


par(plotPar)


```

### Grants and publications

```{r}

plotPar <- par(mfrow = c(2,1), 
               bg = "ivory", 
               fg = "gray20",
               oma = c(1,0,0,0),
               mar = c(3, 4.1, 2, 0.3)
               )



hist(ageData$TOTAL_PUBLICATIONS, col = "darkolivegreen3")

hist(ageData$TOTAL_GRANTS, col = "orchid")

par(plotPar)

```

### Matching confidence

I need a table of the description

```{r}

unique(ageData[, c("CONFIDENCE", "CONFIDENCE_DESC")]) |>
  (\(x){
    x[order(match(x$CONFIDENCE, levels(ageData$CONFIDENCE))),]
    
  })() |>
  kbl(caption = "Confidence ratings and description", row.names = FALSE, col.names = c("", "DESCRIPTION")  ) |>
  column_spec(2, extra_css = "padding-left: 1em;")


```

### NON DUPES

```{r}

# Combining graphic of dupes and non-dupes

# parameters
# incomingPar <- par(mfrow = c(1,3),
#              mar = c(1,2,0,1),
#              oma = c(0,0,2,0))

# Create the layout 
layout(matrix(c(1,1,1,1,2,3,4,5), nrow = 2, byrow = TRUE),
       heights = c(0.3, 1)) 

incomingPar <- par(mar = c(4,3,4,2),
                   oma = c(0,0,3,1))

# Dupes and non-dupes barplot

firstPlot <- barplot(as.matrix(c(length(theDupes), length(unique(ageData$EMPLID)[ageData$EMPLID %in% nonDupes]  ))),
        col = c("pink","gray"),
        main = "COUNT OF PI'S", main.lab = 2,
        horiz = TRUE
        )

singlePercentage <- paste(round(proportions(c(length(theDupes), length(unique(ageData$EMPLID)[ageData$EMPLID %in% nonDupes]  )))[2]*100,0),"%")

text(x = 4000, y = firstPlot,  paste0("SINGLE (", singlePercentage, ")") , col = "purple", cex = 1.6, font =2 )

# text(x = 4000, y = firstPlot,  "SINGLE", col = "purple", cex = 1.6, font =2 )

# text(x = 4000, y = firstPlot*0.7,  paste(round(proportions(c(length(theDupes), length(unique(ageData$EMPLID)[ageData$EMPLID %in% nonDupes]  )))[2]*100,0),"%"), col = "purple", cex = 1.6, font =2 )


text(x = 0.619*length(theDupes), y = firstPlot,  "MULTIPLE", col = "gray30", cex = 1.6, font = 2)


# Graphing duplicates first

par(mar = c(4,4,4,2))

boxplot(theDupes, col = "pink"
        )

mtext(side = 2,
      text = "DUPLICATIONS PER PI",
      line = 2.9,
      font =2,
      col = "gray20")


table(ageData$CONFIDENCE[ageData$EMPLID %in% names(theDupes)]) |>
  barplot(col = c(viridis::viridis(5)[1:5],"grey"))

mtext("MULTIPLE PI MATCHES", at = -2, line = 2, xpd = TRUE)

# mtext("PI duplication and confidence score for duplicate PI matches", outer = TRUE)



# Graphing non-dupes

secondPlot <- barplot(as.matrix(table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes])), col = c(viridis::viridis(5),"gray"),
                      border = NA,
                      ylab = "NON-DUPLICATED PI'S", font.lab = 2,
                      col.lab = "purple")

text(x=secondPlot, y = table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes])[1]*0.619, "CONFIDENCE = 1", col = "ivory", font = 2 , cex = 1.6)

text(x=secondPlot, y = table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes])[1]*0.619 * 0.85, paste0(round(proportions(table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes]))[1]*100,0),"%") , col = "ivory", font = 2 , cex = 1.6)


thirdPlot <- ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes] |>
  table() |>
  (\(x){
    x[names(x) != "1"]
    
  })() |>
  barplot(
    ylab = "NON-DUPLICATED PI'S",
    font.lab = 2,
    col.lab = "purple",
    #ylab = expression(CONFIDENCE != 1),
    #font.lab = 2,
    #col.lab = "gray20",
    col = c(viridis::viridis(5)[2:5],"grey") )


mtext("SINGLE PI MATCHES", at = -2, line = 2, xpd = TRUE)

# mtext("PI duplication and confidence score for non-duplicated PI matches", outer = TRUE)

mtext("Matches per PI and confidence scores", outer = TRUE, font = 2, cex = 1.381)

par(incomingPar)

# It would be great if I had a floating title over the two sub-graphics

```


```{r eval=FALSE}

# I combined the two graphics

# Graphing duplicates

incomingPar <- par(mfrow = c(1,3),
              mar = c(2,4,0,0),
              oma = c(0,0,2,0))

firstPlot <- barplot(as.matrix(c(length(theDupes), length(unique(ageData$EMPLID)[ageData$EMPLID %in% nonDupes]  ))),
        col = c("pink","gray"),
         ylab = "COUNT OF PI'S", font.lab = 2
        )

text( x = firstPlot, y = 4000, "NON-DUPLICATED", col = "purple", cex = 1.6, font =2 )

text( x = firstPlot, y = 4000*0.9, paste(round(proportions(c(length(theDupes), length(unique(ageData$EMPLID)[ageData$EMPLID %in% nonDupes]  )))[2]*100,0),"%"), col = "purple", cex = 1.6, font =2 )


text(x = firstPlot, y = 1000, "DUPLICATED", col = "gray30", cex = 1.6, font = 2)


boxplot(theDupes, col = "pink"
        )

mtext(side = 2,
      text = "DUPLICATIONS PER PI",
      line = 2.9,
      font =2,
      col = "gray20")


table(ageData$CONFIDENCE[ageData$EMPLID %in% names(theDupes)]) |>
  barplot(col = c(viridis::viridis(5)[1:5],"grey"))

mtext("PI duplication and confidence score for duplicate PI matches", outer = TRUE)

par(incomingPar)

# looks great

# should I drill down?
# nah, that's good enough for this report

```

# SUBSET OF INTEREST

Not all `r length(unique(ageData$EMPLID)) |> format(big.mark = ",")` PI's available in the Dimensions data are of immediate interest.  A previous study examined `r length(unique(prepData$PROPOSAL_PI_EMPLID)) |> format(big.mark = ",")` PI's who submitted proposals between FY2013 and FY2023.  



```{r}

all(unique(prepData$PROPOSAL_PI_EMPLID) %in% unique(ageData$EMPLID))

unique(prepData$PROPOSAL_PI_EMPLID)[!(unique(prepData$PROPOSAL_PI_EMPLID)) %in% unique(ageData$EMPLID)] |> length() # 812

# Go back to where I calculated all of this and figure out a way to demonstrate it.

# I think the "subset of interest" is reasonable.

# For the subset of interest--
#  - Repeat the pink/gray "duplication" graphics.
#  - State whether the missing values are random.
#  - And I seriously need better words to describe this.

# I think I'll publish what I have and review.

length(unique(prepAgeData$PROPOSAL_PI_EMPLID[is.na(prepAgeData$CONFIDENCE)]))/length(unique(prepAgeData$PROPOSAL_PI_EMPLID))

c(length(unique(prepAgeData$PROPOSAL_PI_EMPLID[is.na(prepAgeData$CONFIDENCE)])),
  length(unique(prepAgeData$PROPOSAL_PI_EMPLID[!is.na(prepAgeData$CONFIDENCE)]))
  ) |>
  as.matrix() |>
  barplot(col = c("chocolate4", "cyan2"),
          main = "Match found and no match found in Dimensions data")

# This is match found and no match found

```  

And now that I've looked at this long enough,

what I think I'd like is to add the pink and gray bar not as a vertical on the left, but as a horizontal.  Then the two patterns on the right of each pink-and-gray become a row of four underneath the pink or gray,
and maybe have some kind of visual cue.


```{r}

# SUBSET OF INTEREST!
# Graphing non-dupes

dupesSubset <- names(theDupes) %in% prepData$PROPOSAL_PI_EMPLID

nonDupesSubset <- ageData$EMPLID %in% nonDupes[nonDupes %in% prepData$PROPOSAL_PI_EMPLID]

incomingPar <- par(mfrow = c(1,3),
              mar = c(2,4,0,0),
              oma = c(0,0,2,0))

firstPlot <- barplot(as.matrix(c(length(theDupes[dupesSubset]), length(unique(ageData$EMPLID[nonDupesSubset])  ))),
        col = c("pink","gray"),
         ylab = "COUNT OF PI'S", font.lab = 2
        )

text( x = firstPlot, y = 4000, "NON-DUPLICATED", col = "purple", cex = 1.6, font =2 )

text( x = firstPlot, y = 4000*0.9, paste(round(proportions(c(length(theDupes), length(unique(ageData$EMPLID)[ageData$EMPLID %in% nonDupes]  )))[2]*100,0),"%"), col = "purple", cex = 1.6, font =2 )


text(x = firstPlot, y = 1000, "DUPLICATED", col = "gray30", cex = 1.6, font = 2)


secondPlot <- barplot(as.matrix(table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes])), col = c(viridis::viridis(5),"gray"),
                      border = NA,
                      ylab = "NON-DUPLICATED PI'S", font.lab = 2,
                      col.lab = "purple")

text(x=secondPlot, y = table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes])[1]*0.619, "CONFIDENCE = 1", col = "ivory", font = 2 , cex = 1.6)

text(x=secondPlot, y = table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes])[1]*0.619 * 0.85, paste0(round(proportions(table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes]))[1]*100,0),"%") , col = "ivory", font = 2 , cex = 1.6)


thirdPlot <- ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes] |>
  table() |>
  (\(x){
    x[names(x) != "1"]
    
  })() |>
  barplot(
    ylab = "NON-DUPLICATED PI'S",
    font.lab = 2,
    col.lab = "purple",
    #ylab = expression(CONFIDENCE != 1),
    #font.lab = 2,
    #col.lab = "gray20",
    col = c(viridis::viridis(5)[2:5],"grey") )

mtext("PI duplication and confidence score for non-duplicated PI matches", outer = TRUE)

par(incomingPar)



```


```{r}

# SUBSET OF INTEREST!
# Graphing duplicates

incomingPar <- par(mfrow = c(1,3),
              mar = c(2,4,0,0),
              oma = c(0,0,2,0))

firstPlot <- barplot(as.matrix(c(length(theDupes), length(unique(ageData$EMPLID)[ageData$EMPLID %in% nonDupes]  ))),
        col = c("pink","gray"),
         ylab = "COUNT OF PI'S", font.lab = 2
        )

text( x = firstPlot, y = 4000, "NON-DUPLICATED", col = "purple", cex = 1.6, font =2 )

text( x = firstPlot, y = 4000*0.9, paste(round(proportions(c(length(theDupes), length(unique(ageData$EMPLID)[ageData$EMPLID %in% nonDupes]  )))[2]*100,0),"%"), col = "purple", cex = 1.6, font =2 )


text(x = firstPlot, y = 1000, "DUPLICATED", col = "gray30", cex = 1.6, font = 2)


boxplot(theDupes, col = "pink"
        )

mtext(side = 2,
      text = "DUPLICATIONS PER PI",
      line = 2.9,
      font =2,
      col = "gray20")


table(ageData$CONFIDENCE[ageData$EMPLID %in% names(theDupes)]) |>
  barplot(col = c(viridis::viridis(5)[1:5],"grey"))

mtext("PI duplication and confidence score for duplicate PI matches", outer = TRUE)

par(incomingPar)

# looks great

# should I drill down?
# nah, that's good enough for this report

```


You almost want a flow-chart graphic to keep these things straight.



```{r}

####################################################
## USE ML TO SEE IF MISSING VALUES HAVE A PATTERN ##
####################################################

## PREP

### calculate win/loss per pI

fullPI <- calculateWinRates(data = prepData, categoryColumn = "PROPOSAL_PI_EMPLID", functionList = list(mean = mean, median = median)) |> (\(x){ x[[1]] })()

fullPI$count.total <- apply(fullPI[,c("win.count","loss.count")], 1, sum, na.rm = TRUE )
fullPI$sum.total <- apply(fullPI[,c("win.sum","loss.sum")], 1, sum, na.rm = TRUE )

###  extract most common strings and factors for certain columns

theStrings <- c("PROPOSAL_PURPOSE", 
                "PROPOSAL_TYPE", 
                "college",
                "PROPOSAL_RECIPIENT_FUNDING_TYPE",
                "PROPOSAL_FANDA_WAIVER_INDIVATOR",
                "PROPOSAL_COST_SHARE_INDICATOR",
          "PROPOSAL_FANDA_OFF_CAMPUS_RATE_INDICATOR",
                "PROPOSAL_UPLOAD_DATE_FISCAL_YEAR",
                "PROPOSAL_PI_APPOINTMENT_COLLEGE",
                "PROPOSAL_PI_ACADEMIC_RANK",
                "PROPOSAL_PI_TENURE_STATUS",
          "PROPOSAL_PI_FACULTY_CATEGORY",
          "PROPOSAL_PI_FACULTY_SUBCATEGORY",
          "PROPOSAL_PI_ACADEMIC_RANK_LEVEL",
          "PROPOSAL_PI_RANK_SORTED",
          "PROPOSAL_PI_FACULTY_LINE_SORTED",
          "VPR_PROPOSAL_COLLEGE",
          "PROPOSAL_VP",
          "VPR_PROPOSAL_VP",
          "PROPOSAL_SPONSOR_TYPE",
          "PROPOSAL_IACUC_IRB_DIM_KEY",
          "HIGHEST_GOVERNMENT_AGENCY_ACRONYM",
          "NEXT_HIGHEST_GOVERNMENT_AGENCY_ACRONYM",
          "complex_cluster",
          "rate_cluster"
                )

mostCommon_list <- lapply(theStrings, function(theString){
  
  aggregate(get(theString) ~ PROPOSAL_PI_EMPLID,
           data = prepData,
           function(x){ table(as.character(x))[order(table(as.character(x)), decreasing = TRUE)] |> 
               names() |>
               (\(y){y[1]})()
  
  
})
  
}

)

mostCommon <- Reduce(function(x,y){merge(x,y, by = "PROPOSAL_PI_EMPLID", all.x=TRUE)}, mostCommon_list)

names(mostCommon) <- c("PROPOSAL_PI_EMPLID", theStrings)

mostCommon$complex_cluster[is.na(mostCommon$complex_cluster)] <- "unassigned"

mostCommon$rate_cluster[is.na(mostCommon$rate_cluster)] <- "unassigned"

### extract dates

theDates <- aggregate(upload_year ~ PROPOSAL_PI_EMPLID, data = prepData,
function (x) {c(minYr = min(x, na.rm = TRUE),maxYr = max(x, na.rm = TRUE))})

theDates <- cbind(theDates[1], as.data.frame(theDates$upload_year))

theDates$dateRange <- theDates$maxYr - theDates$minYr

# I could pull in something like years since initial hire

# but let's see what this coughs up

### merge back together

fullPI <- merge(fullPI, merge(mostCommon, theDates, by = "PROPOSAL_PI_EMPLID"), by.x = "row.names", by.y = "PROPOSAL_PI_EMPLID" )

row.names(fullPI) <- fullPI$Row.names
names(fullPI)[names(fullPI) %in% "Row.names"] <- "PROPOSAL_PI_EMPLID"

fullPI$class <- ifelse(fullPI$PROPOSAL_PI_EMPLID %in% ageData$EMPLID, "present","missing")

fullPI$class <- factor(fullPI$class)

```


```{r}

## SPLIT

set.seed(42)

splitIndex <- createDataPartition(fullPI$class, p = 0.8, list = FALSE)

trainData <- fullPI[splitIndex,!colnames(fullPI) %in% c("PROPOSAL_PI_EMPLID")]
testData <- fullPI[-splitIndex,!colnames(fullPI) %in% c("PROPOSAL_PI_EMPLID")]

```


```{r eval=FALSE}

## TRAIN

ctrl <- trainControl(
  method = "cv",       # k-fold cross-validation
  number = 5,          # 5-fold CV
  verboseIter = TRUE,  # optional
  classProbs = TRUE,   # needed for AUC/ROC
  summaryFunction = twoClassSummary 
)

set.seed(42)

xgbModel <- train(
  class ~ .,
  data = trainData,
  method = "xgbTree",
  trControl = ctrl,
  metric = "ROC",       # maximize AUC
  preProcess = c("center", "scale"),  # optional
  tuneLength = 5        # try 5 tuning parameter combinations
)

saveRDS(xgbModel, here::here("Robjects", "Identifying missing age values from Dimensions Age Exploratory Data Analysis.rds"))


```

```{r}

### PREDICT

filter <- testData$college != "CTSI" &
          testData$PROPOSAL_IACUC_IRB_DIM_KEY != 3

predProbs <- predict(xgbModel, newdata = testData[filter,], type = "prob")
predClass <- predict(xgbModel, newdata = testData[filter,])

drawCM(confusionMatrix(predClass, testData$class[filter]))

# This is such a border-line result
# Weak signals with all that data, but not *nothing*

```

```{r}

plot(varImp(xgbModel), 20)


```

### VARIABLES THAT PREDICT MISSING VALUES

Conclusion: Missing values aren't random.

```{r}

incomingPar <- par(
  mfrow = c(2,2),
  oma = c(0,0,2,0),
  mar = c(4,4,2,1)
  )

boxplot(maxYr ~ class, data = fullPI,  ylab = "",
        main = "Maximum (?) year")

boxplot(dateRange ~ class, data = fullPI, ylab = "",
        main = "Date range")

boxplot(log(sum.total) ~ class, data = fullPI, ylab = "", main = "Proposal total (log)")

boxplot(sum.rate ~ class, data = fullPI, ylab = "",
        main = "Win rate (sum)")

mtext(side = 3, text = "Variables that distinguish missing values", font = 2, cex = 1.619, outer = TRUE)

par(incomingPar)

```

```{r}

incomingPar <- par(
  mfrow = c(2,2),
  oma = c(0,0,2,0),
  mar = c(4,4,2,1)
  )

plotCategory("PROPOSAL_PI_FACULTY_LINE_SORTED")

plotCategory("PROPOSAL_PI_APPOINTMENT_COLLEGE", wanted_label = c("NNN","other"))

# plotCategory("VPR_PROPOSAL_COLLEGE", wanted_label = "OTHER")

plotCategory("PROPOSAL_PI_FACULTY_LINE_SORTED")

plotCategory("college", wanted_label = c("Bus", "other", "SocBeh","Med",  "FinArt", "SCI" ) )

par(incomingPar)

```





```{r eval=FALSE}

# I'm getting a picture of lots of "other"
# Let's look closer into those top 7

boxplot(maxYr ~ class, data = fullPI)
boxplot(dateRange ~ class, data = fullPI)
boxplot(log(sum.total) ~ class, data = fullPI)
boxplot(sum.total ~ class, data = fullPI, log = "y")
boxplot(sum.rate ~ class, data = fullPI)

# This isn't in the model...
boxplot(count.total ~ class, data = fullPI,log = "y")
# ...even though it's a huge difference

plotCategory("PROPOSAL_PI_FACULTY_LINE_SORTED")

plotCategory("PROPOSAL_PI_APPOINTMENT_COLLEGE")

plotCategory("VPR_PROPOSAL_COLLEGE", wanted_label = "OTHER")

plotCategory("college", wanted_label = c("Bus", "other", "SocBeh","Med",  "FinArt", "SCI" ) ) # "Science",

table(fullPI[,c("PROPOSAL_PI_FACULTY_LINE_SORTED", "class")]) |> 
  
  (\(x){ 
    plot(x,
         main = "PROPOSAL_PI_FACULTY_LINE_SORTED",
         col = c("darkcyan","chocolate4"))
        
    })()
  
  


# I wonder if the character name matters? like shorter names are harder to match?

aggregate(PROPOSAL_PI_NAME ~ class, data = prepAgeData, function(x) { mean(nchar(as.character(x)))   })

    class PROPOSAL_PI_NAME
1 missing         17.38025
2 present         16.12802

# I could turn this into a t-test, see if it's signficant,
# and I could re-run my model.

# Next, I wonder who is the most successful and prolific PI that we haven't found?

# should I add "percentiles" back into this --- naa, I've already scaled amounts

# Let's follow Chat and conduct various statistical tests
# to find the ones that differ, even if they don't matter to the model.

```





```{r eval = FALSE}

# sandbox

####################################################
## USE ML TO SEE IF MISSING VALUES HAVE A PATTERN ##
####################################################

# prep

######################
## CALCULATE PER PI ##
######################

fullPI <- calculateWinRates(data = prepData, categoryColumn = "PROPOSAL_PI_EMPLID", functionList = list(mean = mean, median = median)) |> (\(x){ x[[1]] })()
# really starting to hate the list nature and why do I want "call" ?

fullPI$count.total <- apply(fullPI[,c("win.count","loss.count")], 1, sum, na.rm = TRUE )
fullPI$sum.total <- apply(fullPI[,c("win.sum","loss.sum")], 1, sum, na.rm = TRUE )



mostCommon <- aggregate(cbind(PROPOSAL_PURPOSE, PROPOSAL_TYPE, PROPOSAL_COLLEGE) ~ PROPOSAL_PI_EMPLID,
           data = prepData,
           
           function(x){ table(as.character(x))[order(table(as.character(x)), decreasing = TRUE)] |> 
               names() |>
               (\(y){y[1]})() |>
               list()
             
            }
           
           )


# wow aggregating is aggravating
# no wonder dplyr took off

uniqueValues <- sapply(prepData[, sapply(prepData, is.factor), drop = FALSE], nlevels)

theStrings <- c("PROPOSAL_PURPOSE", 
                "PROPOSAL_TYPE", 
                "college",
                "PROPOSAL_RECIPIENT_FUNDING_TYPE",
                "PROPOSAL_FANDA_WAIVER_INDIVATOR",
                "PROPOSAL_COST_SHARE_INDICATOR",
          "PROPOSAL_FANDA_OFF_CAMPUS_RATE_INDICATOR",
                "PROPOSAL_UPLOAD_DATE_FISCAL_YEAR",
                "PROPOSAL_PI_APPOINTMENT_COLLEGE",
                "PROPOSAL_PI_ACADEMIC_RANK",
                "PROPOSAL_PI_TENURE_STATUS",
          "PROPOSAL_PI_FACULTY_CATEGORY",
          "PROPOSAL_PI_FACULTY_SUBCATEGORY",
          "PROPOSAL_PI_ACADEMIC_RANK_LEVEL",
          "PROPOSAL_PI_RANK_SORTED",
          "PROPOSAL_PI_FACULTY_LINE_SORTED",
          "VPR_PROPOSAL_COLLEGE",
          "PROPOSAL_VP",
          "VPR_PROPOSAL_VP",
          "PROPOSAL_SPONSOR_TYPE",
          "PROPOSAL_IACUC_IRB_DIM_KEY",
          "HIGHEST_GOVERNMENT_AGENCY_ACRONYM",
          "NEXT_HIGHEST_GOVERNMENT_AGENCY_ACRONYM",
          "complex_cluster",
          "rate_cluster"
                )

mostCommon_list <- lapply(theStrings, function(theString){
  
  aggregate(get(theString) ~ PROPOSAL_PI_EMPLID,
           data = prepData,
           function(x){ table(as.character(x))[order(table(as.character(x)), decreasing = TRUE)] |> 
               names() |>
               (\(y){y[1]})()
  
  
})
  
}

)

mostCommon <- Reduce(function(x,y){merge(x,y, by = "PROPOSAL_PI_EMPLID", all.x=TRUE)}, mostCommon_list)

names(mostCommon) <- c("PROPOSAL_PI_EMPLID", theStrings)

mostCommon$complex_cluster[is.na(mostCommon$complex_cluster)] <- "unassigned"

mostCommon$rate_cluster[is.na(mostCommon$rate_cluster)] <- "unassigned"

theDates <- aggregate(upload_year ~ PROPOSAL_PI_EMPLID, data = prepData,
function (x) {c(minYr = min(x, na.rm = TRUE),maxYr = max(x, na.rm = TRUE))})

theDates <- cbind(theDates[1], as.data.frame(theDates$upload_year))



```


```{r}

keepColumns <- c(
 "PROPOSAL_PI_EMPLID",                      
 "PROPOSAL_ID",                             
 "win",                                     
 "PROPOSAL_DIRECT_COST",                    
 "PROPOSAL_FA_COST",                        
 "PROPOSAL_TOTAL_SPONSOR_BUDGET",           
 "PROPOSAL_UNIVERSITY_COSTSHARE",           
 "PROPOSAL_3RD_PARTY_COSTSHARE",            
 "PROPOSAL_DIRECT_COST_prop",               
 "PROPOSAL_FA_COST_prop",                   
 "PROPOSAL_UNIVERSITY_COSTSHARE_prop",      
 "PROPOSAL_3RD_PARTY_COSTSHARE_prop",       
 "PROPOSAL_SHORT_TITLE",                    
 "PROPOSAL_TYPE",                           
 "PROPOSAL_PURPOSE",                        
 "PROPOSAL_RECIPIENT_FUNDING_TYPE",         
 "PROPOSAL_COST_SHARE_INDICATOR",           
 "PROPOSAL_FANDA_WAIVER_INDIVATOR",         
 "PROPOSAL_FANDA_OFF_CAMPUS_RATE_INDICATOR",
 "PROPOSAL_UPLOAD_DATE_FISCAL_YEAR",        
 "PROPOSAL_PI_NAME",                        
 "PROPOSAL_PI_APPOINTMENT_DEPT",            
 "PROPOSAL_PI_APPOINTMENT_COLLEGE",         
 "PROPOSAL_PI_ACADEMIC_RANK",               
 "PROPOSAL_PI_TENURE_STATUS",               
 "PROPOSAL_PI_FACULTY_CATEGORY",            
 "PROPOSAL_PI_FACULTY_SUBCATEGORY",         
 "PROPOSAL_PI_ACADEMIC_RANK_LEVEL",         
 "PROPOSAL_PI_RANK_SORTED",                 
 "PROPOSAL_PI_FACULTY_LINE_SORTED",         
 "PROPOSAL_ORG",                            
 "PROPOSAL_DEPT",                           
 "VPR_PROPOSAL_COLLEGE",                    
 "PROPOSAL_VP",                             
 "VPR_PROPOSAL_VP",                         
 "PROPOSAL_SPONSOR_ID",                     
 "PROPOSAL_SPONSOR_NAME",                   
 "PROPOSAL_SPONSOR_TYPE_CODE",              
 "PROPOSAL_SPONSOR_TYPE",                   
 "PROPOSAL_IACUC_IRB_DIM_KEY",              
 "PROPOSAL_SPO_EMPLID",                     
 "PROPOSAL_SPO_NAME",                       
 "PROPOSAL_CREATION_DATE",                  
 "PROPOSAL_OSP_RECEIVED_DATE",              
 "PROPOSAL_OSP_REVIEW_DATE",                
 "PROPOSAL_UPLOAD_DATE",                    
 "PROPOSAL_PROJECT_START_DATE",             
 "PROPOSAL_PROJECT_END_DATE",               
 "PROPOSAL_SPONSOR_DUE_DATE",               
 "HIGHEST_GOVERNMENT_AGENCY_ACRONYM",       
 "NEXT_HIGHEST_GOVERNMENT_AGENCY_ACRONYM",  
 "PROPOSAL_CREATION_DATE.week",             
 "PROPOSAL_CREATION_DATE.month",           
 "PROPOSAL_OSP_RECEIVED_DATE.week",         
 "PROPOSAL_OSP_RECEIVED_DATE.month",        
"PROPOSAL_OSP_REVIEW_DATE.week",           
 "PROPOSAL_OSP_REVIEW_DATE.month",          
 "PROPOSAL_UPLOAD_DATE.week",               
 "PROPOSAL_UPLOAD_DATE.month",              
 "PROPOSAL_PROJECT_START_DATE.week",        
 "PROPOSAL_PROJECT_START_DATE.month",       
 "PROPOSAL_PROJECT_END_DATE.week",          
 "PROPOSAL_PROJECT_END_DATE.month",         
 "PROPOSAL_SPONSOR_DUE_DATE.week",          
 "PROPOSAL_SPONSOR_DUE_DATE.month",         
 "interval.org",                            
 "win.count.prior.org",                     
 "loss.count.prior.org",                    
 "total.count.prior.org",                   
 "priorOrg",                                
 "interval.PI",                             
 "win.count.prior.PI",                      
 "loss.count.prior.PI",                     
 "total.count.prior.PI",                    
 "priorPI",                                 
 "collegeDiffer",                           
 "upload_year",                             
 "upload_fiscal_year",                      
 "big5",                                    
 "PROPOSAL_COLLEGE",                        
"college16_bigInst",                       
 "college",                                 
 "total_cut",                               
 "complex_cluster",                         
 "rate_cluster",                            
 "combined_cluster",                        
 "FIRST_PUB_YR",                            
 "LAST_PUB_YR",                             
 "TOTAL_PUBLICATIONS",                      
"FIRST_PUB_TITLE",                         
"FIRST_PUB_ID",                            
 "FIRST_GRANT_YR",                          
 "LAST_GRANT_YR",                           
 "TOTAL_GRANTS",                            
 "DIM_ID",                                  
 "CONFIDENCE",                              
 "CONFIDENCE_DESC",                         
 "class"
)

# I think I'm going to aggregate and merge, and be a little more thoughtful about 
# what I am using to predict the missing values

# let's get Kaidon working on this

# write.csv(paste0("'", unique(prepAgeData$PROPOSAL_PI_EMPLID[prepAgeData$class == "missing"])), here::here("Robjects", "missingEmplid.csv"))



```

To Do:

Create some simple visualizations of some of the columns.

Find the most prolific/high win rate individuals who are still missing.

Clean up the visualizations that I have.

For my own edification, compare differences per variable and statistical significance.


```{r eval=FALSE}

# SANDBOX

# I should probably make a table of duplicates or something like that.

table(ageData$CONFIDENCE) |>
  plot(lwd = 40,
       xpd = TRUE,
       col= c(viridis::viridis(5),"gray"))

# some kind of count of unique PI's per confidence level?

ratingsPer <- table(unique(ageData[,c("EMPLID", "CONFIDENCE")])) |>
  as.data.frame.matrix() |>
  (\(x){x[,"sum"] <- apply(x, 1, sum); return(x)  })()
  

dim(ratingsPer[ratingsPer$sum >1,]) # 828 7

# huh

# let's look at that 1:1

theDupes <- table(ageData[,c("EMPLID", "DIM_ID")]) |>
  as.data.frame.matrix() |>
    (\(x){apply(x, 1, sum)  })() |>
    (\(x){x[x>1]})()

# perfect . . . 
# now what?

View(ageData[ageData$EMPLID %in% names(theDupes),])

# struggling to make use of this, actually
# It's missing so-o many values

# And, at this point I kinda want their name

View(prepAgeData[prepAgeData$PROPOSAL_PI_EMPLID %in% names(theDupes), c("PROPOSAL_PI_EMPLID", "PROPOSAL_PI_NAME", "CONFIDENCE" )])

# 00020501 is both a "W" and a "1".  Interesting.

# I want to describe what proportion of the ~3000 PI's in my data are covered at which confidence level.

# I want to describe what proportion/count of the Age data
# have no duplicates
# have no duplicates and at which confidence level
# Among the duplicates--
#   How many matches
#   How many matches at which confidence level

length(theDupes)/length(unique(ageData$EMPLID))

barplot(as.matrix(c(length(theDupes), length(unique(ageData$EMPLID)[!unique(ageData$EMPLID) %in% names(theDupes)]  ))))

nonDupes <- unique(ageData$EMPLID)[!unique(ageData$EMPLID) %in% names(theDupes)]  

# I'd like multiple bar plots here in a row
# Next one is non-dupes at which confidence level

table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes], useNA = "always")

barplot(as.matrix(table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes])), col = viridis::viridis(5)) # stack actually looks bad in this case

barplot((table(ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes])), col = c(viridis::viridis(5),"gray") )


ageData$CONFIDENCE[ageData$EMPLID %in% nonDupes] |>
  table() |>
  (\(x){
    x[names(x) != "1"]
    
  })() |>
  barplot(col = c(viridis::viridis(5)[2:5],"grey") )


```



